{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "sys.path.append('../CNN')\n",
    "import utils_CNN as utils\n",
    "\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mix_sample_from(npy_dirs: list, nevents: tuple, seed=0):\n",
    "    # npy_dirs: list of npy directories\n",
    "    # nevents: tuple of (n_sig_SR, n_sig_SB, n_bkg_SR, n_bkg_SB)\n",
    "    data = None\n",
    "    label = None\n",
    "\n",
    "    data_sig_SR = np.load(os.path.join(npy_dirs[0], 'sig_in_SR-data.npy'))\n",
    "    data_sig_SB = np.load(os.path.join(npy_dirs[0], 'sig_in_SB-data.npy'))\n",
    "    data_bkg_SR = np.load(os.path.join(npy_dirs[0], 'bkg_in_SR-data.npy'))\n",
    "    data_bkg_SB = np.load(os.path.join(npy_dirs[0], 'bkg_in_SB-data.npy'))\n",
    "\n",
    "    n_sig_SR, n_sig_SB, n_bkg_SR, n_bkg_SB = nevents\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    idx_sig_SR = np.random.choice(data_sig_SR.shape[0], n_sig_SR, replace=False)\n",
    "    idx_sig_SB = np.random.choice(data_sig_SB.shape[0], n_sig_SB, replace=False)\n",
    "    idx_bkg_SR = np.random.choice(data_bkg_SR.shape[0], n_bkg_SR, replace=False)\n",
    "    idx_bkg_SB = np.random.choice(data_bkg_SB.shape[0], n_bkg_SB, replace=False)\n",
    "\n",
    "    print(f'Preparing dataset from {npy_dirs}')\n",
    "    for npy_dir in npy_dirs:\n",
    "\n",
    "        data_sig_SR = np.load(os.path.join(npy_dir, 'sig_in_SR-data.npy'))\n",
    "        data_sig_SB = np.load(os.path.join(npy_dir, 'sig_in_SB-data.npy'))\n",
    "        data_bkg_SR = np.load(os.path.join(npy_dir, 'bkg_in_SR-data.npy'))\n",
    "        data_bkg_SB = np.load(os.path.join(npy_dir, 'bkg_in_SB-data.npy'))\n",
    "\n",
    "        new_data = np.concatenate([\n",
    "            data_sig_SR[idx_sig_SR],\n",
    "            data_bkg_SR[idx_bkg_SR],\n",
    "            data_sig_SB[idx_sig_SB],\n",
    "            data_bkg_SB[idx_bkg_SB]\n",
    "        ], axis=0)\n",
    "\n",
    "        if data is None:\n",
    "            data = new_data\n",
    "        else:\n",
    "            data = np.concatenate([data, new_data], axis=0)\n",
    "\n",
    "        new_label = np.zeros(sum(nevents))\n",
    "        new_label[:n_sig_SR + n_bkg_SR] = 1\n",
    "\n",
    "        if label is None:\n",
    "            label = new_label\n",
    "        else:\n",
    "            label = np.concatenate([label, new_label])\n",
    "\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_dir = Path('./SB_0_npy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../CNN/config_files/origin_25x25_config_01.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config file\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "train_npy_paths = [\"../Sample/HVmodel/data/origin/25x25\"]\n",
    "val_npy_paths = [\"../Sample/HVmodel/data/origin/25x25/val\"]\n",
    "\n",
    "sensitivity = 0.0\n",
    "luminosity = 139\n",
    "\n",
    "true_label_path = \"../Sample/HVmodel/data/split_val/25x25/mix_sample_test.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing seed 123\n",
      "Background cross section, SR: 136.13 fb, SB: 145.57 fb\n",
      "Background sample size: SR: 18922.4, SB: 20234.0\n",
      "Signal sample size: SR: 0.0, SB: 0.0\n",
      "Preparing dataset from ['../Sample/HVmodel/data/origin/25x25']\n",
      "(31324, 25, 25, 2)\n",
      "Preparing dataset from ['../Sample/HVmodel/data/origin/25x25/val']\n",
      "Processing seed 223\n",
      "Background cross section, SR: 136.13 fb, SB: 145.57 fb\n",
      "Background sample size: SR: 18922.4, SB: 20234.0\n",
      "Signal sample size: SR: 0.0, SB: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m n_SR_S, n_SR_B, n_SB_S, n_SB_B \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcompute_nevent_in_SR_SB(sensitivity\u001b[38;5;241m=\u001b[39msensitivity, L\u001b[38;5;241m=\u001b[39mluminosity)\n\u001b[1;32m     10\u001b[0m train_nevents \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marray([n_SR_S, n_SB_S, n_SR_B, n_SB_B]) \u001b[38;5;241m*\u001b[39m r_train)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_mix_sample_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_npy_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_nevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# save the dataset\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mcreate_mix_sample_from\u001b[0;34m(npy_dirs, nevents, seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m data_sig_SB \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(npy_dirs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msig_in_SB-data.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      9\u001b[0m data_bkg_SR \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(npy_dirs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbkg_in_SR-data.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 10\u001b[0m data_bkg_SB \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpy_dirs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbkg_in_SB-data.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m n_sig_SR, n_sig_SB, n_bkg_SR, n_bkg_SB \u001b[38;5;241m=\u001b[39m nevents\n\u001b[1;32m     14\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n",
      "File \u001b[0;32m~/.conda/envs/jupyter/lib/python3.8/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/.conda/envs/jupyter/lib/python3.8/site-packages/numpy/lib/format.py:801\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 801\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    814\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for seed in range(123, 1100, 100):\n",
    "    print(f'Processing seed {seed}')\n",
    "    if not os.path.exists(npy_dir / f'{seed}'):\n",
    "        os.makedirs(npy_dir / f'{seed}')\n",
    "\n",
    "    # Sampling dataset\n",
    "    r_train, r_val = 0.8, 0.2\n",
    "    n_SR_S, n_SR_B, n_SB_S, n_SB_B = utils.compute_nevent_in_SR_SB(sensitivity=sensitivity, L=luminosity)\n",
    "\n",
    "    train_nevents = (np.array([n_SR_S, n_SB_S, n_SR_B, n_SB_B]) * r_train).astype(int)\n",
    "    X_train, y_train = create_mix_sample_from(train_npy_paths, train_nevents, seed=seed)\n",
    "\n",
    "    # save the dataset\n",
    "    np.save(npy_dir / f'{seed}/train-data.npy', X_train)\n",
    "    np.save(npy_dir / f'{seed}/train-label.npy', y_train)\n",
    "\n",
    "    val_nevents = (np.array([n_SR_S, n_SB_S, n_SR_B, n_SB_B]) * r_val).astype(int)\n",
    "    X_val, y_val = create_mix_sample_from(val_npy_paths, val_nevents, seed=seed)\n",
    "\n",
    "    # save the dataset\n",
    "    np.save(npy_dir / f'{seed}/val-data.npy', X_val)\n",
    "    np.save(npy_dir / f'{seed}/val-label.npy', y_val)\n",
    "\n",
    "    # save the true label\n",
    "    X_test, y_test = utils.load_samples(true_label_path)\n",
    "    X_test_B = X_test[y_test == 0]\n",
    "\n",
    "    np.save(npy_dir / f'{seed}/test-data.npy', X_test_B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
