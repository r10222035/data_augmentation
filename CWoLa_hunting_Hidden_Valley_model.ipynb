{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sample preparation\n",
    "* Generate .root file\n",
    "* Select the events and save jet constitutent information to .h5 file\n",
    "    - Sample/from_root_to_h5.py\n",
    "* Generate mixed sample\n",
    "    - split training and validation datasets\n",
    "    - true label testing dataset\n",
    "* Data augmentation\n",
    "    - optional\n",
    "    - apply on training dataset\n",
    "    - Sample/physical_augmentation_h5.ipynb\n",
    "* From .h5 file generate jet image and save in .npy file\n",
    "    - Sample/from_h5_to_npy.py\n",
    "2. CNN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From root to h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_root_to_h5.py ../../Software/pythia8307/HVmodel/test_100k-1.root ./HVmodel/data/split_val/signal.h5 1 &\n",
      "python from_root_to_h5.py ../../Software/pythia8307/HVmodel/test_100k-2.root ./HVmodel/data/split_val/signal-val.h5 1 &\n",
      "python from_root_to_h5.py ../../Software/pythia8307/HVmodel/test_100k-3.root ./HVmodel/data/split_val/signal-test.h5 1 &\n",
      "python from_root_to_h5.py ./ppjj/Events/run_03/tag_1_delphes_events.root ./HVmodel/data/split_val/background_03.h5 0 &\n",
      "python from_root_to_h5.py ./ppjj/Events/run_04/tag_1_delphes_events.root ./HVmodel/data/split_val/background_04.h5 0 &\n",
      "python from_root_to_h5.py ./ppjj/Events/run_05/tag_1_delphes_events.root ./HVmodel/data/split_val/background-val.h5 0 &\n",
      "python from_root_to_h5.py ./ppjj/Events/run_06/tag_1_delphes_events.root ./HVmodel/data/split_val/background-test.h5 0 &\n",
      "python from_root_to_h5.py ./ppjj/Events/run_07/tag_1_delphes_events.root ./HVmodel/data/split_val/background_07.h5 0 &\n"
     ]
    }
   ],
   "source": [
    "root_path = '../../Software/pythia8307/HVmodel/test_100k-1.root'\n",
    "output_path = './HVmodel/data/split_val/signal.h5'\n",
    "sample_type = 1\n",
    "\n",
    "cmd = f'python from_root_to_h5.py {root_path} {output_path} {sample_type} &'\n",
    "print(cmd)\n",
    "\n",
    "root_path = '../../Software/pythia8307/HVmodel/test_100k-2.root'\n",
    "output_path = './HVmodel/data/split_val/signal-val.h5'\n",
    "sample_type = 1\n",
    "\n",
    "cmd = f'python from_root_to_h5.py {root_path} {output_path} {sample_type} &'\n",
    "print(cmd)\n",
    "\n",
    "root_path = '../../Software/pythia8307/HVmodel/test_100k-3.root'\n",
    "output_path = './HVmodel/data/split_val/signal-test.h5'\n",
    "sample_type = 1\n",
    "\n",
    "cmd = f'python from_root_to_h5.py {root_path} {output_path} {sample_type} &'\n",
    "print(cmd)\n",
    "\n",
    "root_path = './ppjj/Events/run_03/tag_1_delphes_events.root'\n",
    "output_path = './HVmodel/data/split_val/background_03.h5'\n",
    "sample_type = 0\n",
    "\n",
    "cmd = f'python from_root_to_h5.py {root_path} {output_path} {sample_type} &'\n",
    "print(cmd)\n",
    "\n",
    "root_path = './ppjj/Events/run_04/tag_1_delphes_events.root'\n",
    "output_path = './HVmodel/data/split_val/background_04.h5'\n",
    "sample_type = 0\n",
    "\n",
    "cmd = f'python from_root_to_h5.py {root_path} {output_path} {sample_type} &'\n",
    "print(cmd)\n",
    "\n",
    "root_path = './ppjj/Events/run_05/tag_1_delphes_events.root'\n",
    "output_path = './HVmodel/data/split_val/background-val.h5'\n",
    "sample_type = 0\n",
    "\n",
    "cmd = f'python from_root_to_h5.py {root_path} {output_path} {sample_type} &'\n",
    "print(cmd)\n",
    "\n",
    "root_path = './ppjj/Events/run_06/tag_1_delphes_events.root'\n",
    "output_path = './HVmodel/data/split_val/background-test.h5'\n",
    "sample_type = 0\n",
    "\n",
    "cmd = f'python from_root_to_h5.py {root_path} {output_path} {sample_type} &'\n",
    "print(cmd)\n",
    "\n",
    "root_path = './ppjj/Events/run_07/tag_1_delphes_events.root'\n",
    "output_path = './HVmodel/data/split_val/background_07.h5'\n",
    "sample_type = 0\n",
    "\n",
    "cmd = f'python from_root_to_h5.py {root_path} {output_path} {sample_type} &'\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mixed sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.20/08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ROOT\n",
    "\n",
    "ROOT.gROOT.ProcessLine('.include /usr/local/Delphes-3.4.2/')\n",
    "ROOT.gROOT.ProcessLine('.include /usr/local/Delphes-3.4.2/external/')\n",
    "ROOT.gInterpreter.Declare('#include \"/usr/local/Delphes-3.4.2/classes/DelphesClasses.h\"')\n",
    "ROOT.gInterpreter.Declare('#include \"/usr/local/Delphes-3.4.2/external/ExRootAnalysis/ExRootTreeReader.h\"')\n",
    "ROOT.gInterpreter.Declare('#include \"/usr/local/Delphes-3.4.2/external/ExRootAnalysis/ExRootConfReader.h\"')\n",
    "ROOT.gInterpreter.Declare('#include \"/usr/local/Delphes-3.4.2/external/ExRootAnalysis/ExRootTask.h\"')\n",
    "ROOT.gSystem.Load(\"/usr/local/Delphes-3.4.2/install/lib/libDelphes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mjets(*arg):\n",
    "    # arg: list of jets\n",
    "    # return: invariant mass of jets\n",
    "    e_tot, px_tot, py_tot, pz_tot = 0, 0, 0, 0\n",
    "    \n",
    "    for jet in arg:\n",
    "        pt, eta, phi, m = jet[0], jet[1], jet[2], jet[3]\n",
    "        \n",
    "        px, py, pz = pt*np.cos(phi), pt*np.sin(phi), pt*np.sinh(eta)\n",
    "        e = np.sqrt(m**2 + px**2 + py**2 + pz**2)\n",
    "        \n",
    "        px_tot += px\n",
    "        py_tot += py\n",
    "        pz_tot += pz\n",
    "        e_tot += e\n",
    "    \n",
    "    return np.sqrt(e_tot**2 - px_tot**2 - py_tot**2 - pz_tot**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HV_selection(tree):\n",
    "    # Hidden Valley model selection\n",
    "    # 1. 2 jets\n",
    "    # 2. pT > 750 GeV\n",
    "    # 3. |eta| < 2.0\n",
    "\n",
    "    SRSB_region = [4400, 4700, 5500, 5800]\n",
    "\n",
    "    n_event_count = 0\n",
    "    n_jet_count = 0\n",
    "    jet_pt_count = 0\n",
    "    jet_eta_count = 0\n",
    "    mjjs = []\n",
    "\n",
    "    pt = [[],[]]\n",
    "\n",
    "    for event_id, event in tqdm(enumerate(tree)):\n",
    "        n_event_count += 1\n",
    "\n",
    "        if event.Jet_size < 2:\n",
    "            continue\n",
    "        n_jet_count += 1\n",
    "\n",
    "        pt[0].append(event.Jet[0].PT)\n",
    "        pt[1].append(event.Jet[1].PT)\n",
    "        if event.Jet[1].PT < 750:\n",
    "            continue\n",
    "        jet_pt_count += 1\n",
    "\n",
    "        if abs(event.Jet[0].Eta) > 2.0 or abs(event.Jet[1].Eta) > 2.0:\n",
    "            continue\n",
    "        jet_eta_count += 1\n",
    "\n",
    "        jets = [[event.Jet[i].PT, event.Jet[i].Eta, event.Jet[i].Phi, event.Jet[i].Mass] for i in range(2)]\n",
    "        mjj = Mjets(*jets)\n",
    "        mjjs.append(mjj)\n",
    "\n",
    "        if mjj < SRSB_region[0] or mjj > SRSB_region[3]:\n",
    "            continue\n",
    "\n",
    "\n",
    "    mjjs = np.array(mjjs)\n",
    "    SR_count = ((mjjs > SRSB_region[1]) & (mjjs < SRSB_region[2])).sum()\n",
    "    SB_count = (((mjjs > SRSB_region[0]) & (mjjs < SRSB_region[1])) | ((mjjs > SRSB_region[2]) & (mjjs < SRSB_region[3]))).sum()\n",
    "\n",
    "    cutflow_number = {\n",
    "        'Total': n_event_count,\n",
    "        'n jet cut': n_jet_count,\n",
    "        'jet pt cut': jet_pt_count,\n",
    "        'jet eta cut': jet_eta_count,\n",
    "        'Signal region': SR_count,\n",
    "        'Sideband region': SB_count,\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        'mjj': mjjs,\n",
    "        'pt': np.array(pt),\n",
    "        'cutflow_number': cutflow_number,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [08:58, 185.74it/s]\n"
     ]
    }
   ],
   "source": [
    "root_file = '../Software/pythia8307/HVmodel/test_100k-1.root'\n",
    "f = ROOT.TFile(root_file)\n",
    "tree_s = f.Get(\"Delphes\")\n",
    "\n",
    "results_s = HV_selection(tree_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [07:45, 215.05it/s]\n",
      "Warning in <TStreamerInfo::BuildCheck>: \n",
      "   The StreamerInfo for version 2 of class GenParticle read from the file ./Sample/ppjj/Events/run_02/tag_1_delphes_events.root\n",
      "   has a different checksum than the previously loaded StreamerInfo.\n",
      "   Reading objects of type GenParticle from the file ./Sample/ppjj/Events/run_02/tag_1_delphes_events.root \n",
      "   (and potentially other files) might not work correctly.\n",
      "   Most likely the version number of the class was not properly\n",
      "   updated [See ClassDef(GenParticle,2)].\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 2 of class 'GenParticle' differs from \n",
      "the in-memory layout version 2:\n",
      "   float T; //number\n",
      "vs\n",
      "   float CtgTheta; //number\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 2 of class 'GenParticle' differs from \n",
      "the in-memory layout version 2:\n",
      "   float X; //number\n",
      "vs\n",
      "   float D0; //number\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 2 of class 'GenParticle' differs from \n",
      "the in-memory layout version 2:\n",
      "   float Y; //number\n",
      "vs\n",
      "   float DZ; //number\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 2 of class 'GenParticle' differs from \n",
      "the in-memory layout version 2:\n",
      "   float Z; //number\n",
      "vs\n",
      "   float T; //number\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 2 of class 'GenParticle' is missing from \n",
      "the on-file layout version 2:\n",
      "   float X; //number\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 2 of class 'GenParticle' is missing from \n",
      "the on-file layout version 2:\n",
      "   float Y; //number\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 2 of class 'GenParticle' is missing from \n",
      "the on-file layout version 2:\n",
      "   float Z; //number\n",
      "Error in <TObjArray::At>: index 33 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 34 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 35 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 36 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 37 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 38 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 39 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 40 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 41 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 42 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 43 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 44 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 45 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 46 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Error in <TObjArray::At>: index 47 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TStreamerInfo::BuildCheck>: \n",
      "   The StreamerInfo for version 3 of class Track read from the file ./Sample/ppjj/Events/run_02/tag_1_delphes_events.root\n",
      "   has a different checksum than the previously loaded StreamerInfo.\n",
      "   Reading objects of type Track from the file ./Sample/ppjj/Events/run_02/tag_1_delphes_events.root \n",
      "   (and potentially other files) might not work correctly.\n",
      "   Most likely the version number of the class was not properly\n",
      "   updated [See ClassDef(Track,3)].\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float C; //\n",
      "vs\n",
      "   float EtaOuter; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float Mass; //\n",
      "vs\n",
      "   float PhiOuter; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float EtaOuter; //\n",
      "vs\n",
      "   float T; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float PhiOuter; //\n",
      "vs\n",
      "   float X; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float T; //\n",
      "vs\n",
      "   float Y; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float X; //\n",
      "vs\n",
      "   float Z; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float Y; //\n",
      "vs\n",
      "   float TOuter; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float Z; //\n",
      "vs\n",
      "   float XOuter; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float TOuter; //\n",
      "vs\n",
      "   float YOuter; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float XOuter; //\n",
      "vs\n",
      "   float ZOuter; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float YOuter; //\n",
      "vs\n",
      "   float Xd; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float ZOuter; //\n",
      "vs\n",
      "   float Yd; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float Xd; //\n",
      "vs\n",
      "   float Zd; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float Yd; //\n",
      "vs\n",
      "   float L; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float Zd; //\n",
      "vs\n",
      "   float D0; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float L; //\n",
      "vs\n",
      "   float DZ; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float D0; //\n",
      "vs\n",
      "   float ErrorP; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float DZ; //\n",
      "vs\n",
      "   float ErrorPT; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float Nclusters; //\n",
      "vs\n",
      "   float ErrorPhi; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float dNdx; //\n",
      "vs\n",
      "   float ErrorCtgTheta; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float ErrorP; //\n",
      "vs\n",
      "   float ErrorT; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float ErrorPT; //\n",
      "vs\n",
      "   float ErrorD0; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float ErrorPhi; //\n",
      "vs\n",
      "   float ErrorDZ; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float ErrorCtgTheta; //\n",
      "vs\n",
      "   TRef Particle; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 3 of class 'Track' differs from \n",
      "the in-memory layout version 3:\n",
      "   float ErrorT; //\n",
      "vs\n",
      "   int VertexIndex; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorD0; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorDZ; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorC; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorD0Phi; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorD0C; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorD0DZ; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorD0CtgTheta; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorPhiC; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorPhiDZ; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorPhiCtgTheta; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorCDZ; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorCCtgTheta; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   float ErrorDZCtgTheta; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   TRef Particle; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 3 of class 'Track' is missing from \n",
      "the on-file layout version 3:\n",
      "   int VertexIndex; //\n",
      "Error in <TObjArray::At>: index 42 out of bounds (size: 42, this: 0x5579dd690180)\n",
      "Error in <TObjArray::At>: index 43 out of bounds (size: 42, this: 0x5579dd690180)\n",
      "Warning in <TStreamerInfo::BuildCheck>: \n",
      "   The StreamerInfo for version 4 of class Jet read from the file ./Sample/ppjj/Events/run_02/tag_1_delphes_events.root\n",
      "   has a different checksum than the previously loaded StreamerInfo.\n",
      "   Reading objects of type Jet from the file ./Sample/ppjj/Events/run_02/tag_1_delphes_events.root \n",
      "   (and potentially other files) might not work correctly.\n",
      "   Most likely the version number of the class was not properly\n",
      "   updated [See ClassDef(Jet,4)].\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   float NeutralEnergyFraction; //\n",
      "vs\n",
      "   float Beta; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   float ChargedEnergyFraction; //\n",
      "vs\n",
      "   float BetaStar; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   float Beta; //\n",
      "vs\n",
      "   float MeanSqDeltaR; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   float BetaStar; //\n",
      "vs\n",
      "   float PTD; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   float MeanSqDeltaR; //\n",
      "vs\n",
      "   float FracPt; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   float PTD; //\n",
      "vs\n",
      "   float Tau; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   float FracPt; //\n",
      "vs\n",
      "   TLorentzVector SoftDroppedJet; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   float Tau; //\n",
      "vs\n",
      "   TLorentzVector SoftDroppedSubJet1; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   TLorentzVector SoftDroppedJet; //\n",
      "vs\n",
      "   TLorentzVector SoftDroppedSubJet2; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   TLorentzVector SoftDroppedSubJet1; //\n",
      "vs\n",
      "   TLorentzVector TrimmedP4; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   TLorentzVector SoftDroppedSubJet2; //\n",
      "vs\n",
      "   TLorentzVector PrunedP4; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   TLorentzVector TrimmedP4; //\n",
      "vs\n",
      "   TLorentzVector SoftDroppedP4; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   TLorentzVector PrunedP4; //\n",
      "vs\n",
      "   int NSubJetsTrimmed; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   TLorentzVector SoftDroppedP4; //\n",
      "vs\n",
      "   int NSubJetsPruned; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   int NSubJetsTrimmed; //\n",
      "vs\n",
      "   int NSubJetsSoftDropped; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   int NSubJetsPruned; //\n",
      "vs\n",
      "   double ExclYmerge23; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   int NSubJetsSoftDropped; //\n",
      "vs\n",
      "   double ExclYmerge34; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   double ExclYmerge23; //\n",
      "vs\n",
      "   double ExclYmerge45; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   double ExclYmerge34; //\n",
      "vs\n",
      "   double ExclYmerge56; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   double ExclYmerge45; //\n",
      "vs\n",
      "   TRefArray Constituents; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   double ExclYmerge56; //\n",
      "vs\n",
      "   TRefArray Particles; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the on-file layout version 4 of class 'Jet' differs from \n",
      "the in-memory layout version 4:\n",
      "   TRefArray Constituents; //\n",
      "vs\n",
      "   TLorentzVector Area; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 4 of class 'Jet' is missing from \n",
      "the on-file layout version 4:\n",
      "   TRefArray Particles; //\n",
      "Warning in <TStreamerInfo::CompareContent>: The following data member of\n",
      "the in-memory layout version 4 of class 'Jet' is missing from \n",
      "the on-file layout version 4:\n",
      "   TLorentzVector Area; //\n",
      "Error in <TObjArray::At>: index 35 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorC\n",
      "Error in <TObjArray::At>: index 36 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorD0Phi\n",
      "Error in <TObjArray::At>: index 37 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorD0C\n",
      "Error in <TObjArray::At>: index 38 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorD0DZ\n",
      "Error in <TObjArray::At>: index 39 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorD0CtgTheta\n",
      "Error in <TObjArray::At>: index 40 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorPhiC\n",
      "Error in <TObjArray::At>: index 41 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorPhiDZ\n",
      "Error in <TObjArray::At>: index 42 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorPhiCtgTheta\n",
      "Error in <TObjArray::At>: index 43 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorCDZ\n",
      "Error in <TObjArray::At>: index 44 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorCCtgTheta\n",
      "Error in <TObjArray::At>: index 45 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: Track subbranch: Track.ErrorDZCtgTheta\n",
      "Error in <TObjArray::At>: index 35 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorC\n",
      "Error in <TObjArray::At>: index 36 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorD0Phi\n",
      "Error in <TObjArray::At>: index 37 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorD0C\n",
      "Error in <TObjArray::At>: index 38 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorD0DZ\n",
      "Error in <TObjArray::At>: index 39 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorD0CtgTheta\n",
      "Error in <TObjArray::At>: index 40 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorPhiC\n",
      "Error in <TObjArray::At>: index 41 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorPhiDZ\n",
      "Error in <TObjArray::At>: index 42 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorPhiCtgTheta\n",
      "Error in <TObjArray::At>: index 43 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorCDZ\n",
      "Error in <TObjArray::At>: index 44 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorCCtgTheta\n",
      "Error in <TObjArray::At>: index 45 out of bounds (size: 33, this: 0x5579dd5e5fa0)\n",
      "Warning in <TBranchElement::InitializeOffsets>: No streamer element for branch: EFlowTrack subbranch: EFlowTrack.ErrorDZCtgTheta\n"
     ]
    }
   ],
   "source": [
    "root_file = './Sample/ppjj/Events/run_02/tag_1_delphes_events.root'\n",
    "f = ROOT.TFile(root_file)\n",
    "tree_b = f.Get(\"Delphes\")\n",
    "\n",
    "results_b = HV_selection(tree_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified SB region to 4400-4700, 5500-5800\n",
    "np.save('./Sample/HVmodel/data/selection_results_SB_4400_5800_s.npy', results_s)\n",
    "np.save('./Sample/HVmodel/data/selection_results_SB_4400_5800_b.npy', results_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(path):\n",
    "    # path: run path\n",
    "    name = os.path.split(path)[1]\n",
    "\n",
    "    with open(os.path.join(path, f'{name}_tag_1_banner.txt')) as f:\n",
    "        for line in f.readlines():\n",
    "                \n",
    "            #  Integrated weight (pb)  :       0.020257\n",
    "            match = re.match('#  Integrated weight \\(pb\\)  : +(\\d+\\.\\d+)', line)\n",
    "            if match:\n",
    "                # unit: fb\n",
    "                cross_section = float(match.group(1)) * 1000\n",
    "            # #  Number of Events        :       100000\n",
    "            match = re.match('#  Number of Events        :       (\\d+)', line)\n",
    "            if match:\n",
    "                # unit: fb\n",
    "                nevent = int(match.group(1))\n",
    "    \n",
    "    return cross_section, nevent\n",
    "\n",
    "def get_dataset_keys(f):\n",
    "    keys = []\n",
    "    f.visit(lambda key : keys.append(key) if isinstance(f[key], h5py.Dataset) else None)\n",
    "    return keys\n",
    "\n",
    "def create_dataset(f, nevent, MAX_JETS):\n",
    "\n",
    "    f.create_dataset('J1/MASK', (nevent, MAX_JETS), maxshape=(None, MAX_JETS), dtype='|b1')\n",
    "    f.create_dataset('J1/pt', (nevent, MAX_JETS), maxshape=(None, MAX_JETS), dtype='<f4')\n",
    "    f.create_dataset('J1/eta', (nevent, MAX_JETS), maxshape=(None, MAX_JETS), dtype='<f4')\n",
    "    f.create_dataset('J1/phi', (nevent, MAX_JETS), maxshape=(None, MAX_JETS), dtype='<f4')\n",
    "\n",
    "    f.create_dataset('J2/MASK', (nevent, MAX_JETS), maxshape=(None, MAX_JETS), dtype='|b1')\n",
    "    f.create_dataset('J2/pt', (nevent, MAX_JETS), maxshape=(None, MAX_JETS), dtype='<f4')\n",
    "    f.create_dataset('J2/eta', (nevent, MAX_JETS), maxshape=(None, MAX_JETS), dtype='<f4')\n",
    "    f.create_dataset('J2/phi', (nevent, MAX_JETS), maxshape=(None, MAX_JETS), dtype='<f4')\n",
    "\n",
    "    f.create_dataset('EVENT/Mjj', (nevent,), maxshape=(None,), dtype='<f4')\n",
    "    f.create_dataset('EVENT/signal', (nevent,), maxshape=(None,), dtype='<i8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_s = np.load('./Sample/HVmodel/data/selection_results_SB_4400_5800_s.npy', allow_pickle=True).item()\n",
    "results_b = np.load('./Sample/HVmodel/data/selection_results_SB_4400_5800_b.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6837.392481 1000000\n",
      "Background cross section, SR: 136.13 fb, SB: 145.57 fb\n",
      "Background sample size: SR: 75689.7, SB: 80935.9\n",
      "275.11754082386454 67.00583183055264\n"
     ]
    }
   ],
   "source": [
    "# Total cross section and number of events\n",
    "xection, tot_event = get_info('./Sample/ppjj/Events/run_03')\n",
    "print(xection, tot_event)\n",
    "\n",
    "# cross section in signal region and sideband region\n",
    "cross_section_SR = results_b['cutflow_number']['Signal region'] / results_b['cutflow_number']['Total'] * xection\n",
    "cross_section_SB = results_b['cutflow_number']['Sideband region'] / results_b['cutflow_number']['Total'] * xection\n",
    "print(f'Background cross section, SR: {cross_section_SR:.2f} fb, SB: {cross_section_SB:.2f} fb')\n",
    "\n",
    "# number of background events in signal region and sideband region\n",
    "L = 139 * 4\n",
    "n_SR_B = cross_section_SR * L\n",
    "n_SB_B = cross_section_SB * L\n",
    "\n",
    "print(f'Background sample size: SR: {n_SR_B:.1f}, SB: {n_SB_B:.1f}')\n",
    "\n",
    "sensitivity = 1\n",
    "n_SR_S = sensitivity * np.sqrt(n_SR_B)\n",
    "n_SB_S = n_SR_S * results_s['cutflow_number']['Sideband region'] / results_s['cutflow_number']['Signal region']\n",
    "print(n_SR_S, n_SB_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation splitting ratio\n",
    "r_train = 0.8\n",
    "r_val = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mix_sample_from_numbers(sig_path, bkg_path, n_sig_1, n_sig_2, n_bkg_1, n_bkg_2, output_path, SRSB_region=[4400, 4700, 5500, 5800]):\n",
    "    # n_sig_1: number of signal events in mixing sample 1 (Signal region)\n",
    "    # n_sig_2: number of signal events in mixing sample 2 (Sideband region)\n",
    "\n",
    "    nevent = n_sig_1 + n_sig_2 + n_bkg_1 + n_bkg_2\n",
    "    with h5py.File(output_path, 'w') as f_out:\n",
    "        MAX_JETS = 300 \n",
    "        create_dataset(f_out, nevent, MAX_JETS)\n",
    "\n",
    "        keys = get_dataset_keys(f_out)\n",
    "        with h5py.File(sig_path, 'r') as f_sig, h5py.File(bkg_path, 'r') as f_bkg:  \n",
    "            mjj_s = f_sig['EVENT/Mjj'][:]\n",
    "            mjj_b = f_bkg['EVENT/Mjj'][:]\n",
    "            SR_range_s = (mjj_s > SRSB_region[1]) & (mjj_s < SRSB_region[2])\n",
    "            SB_range_s = ((mjj_s > SRSB_region[0]) & (mjj_s < SRSB_region[1])) | ((mjj_s > SRSB_region[2]) & (mjj_s < SRSB_region[3]))\n",
    "            SR_range_b = (mjj_b > SRSB_region[1]) & (mjj_b < SRSB_region[2])\n",
    "            SB_range_b = ((mjj_b > SRSB_region[0]) & (mjj_b < SRSB_region[1])) | ((mjj_b > SRSB_region[2]) & (mjj_b < SRSB_region[3]))\n",
    "\n",
    "            for key in keys:\n",
    "                f_out[key][:n_sig_1] = f_sig[key][:][SR_range_s][:n_sig_1]\n",
    "                f_out[key][n_sig_1:n_sig_1+n_bkg_1] = f_bkg[key][:][SR_range_b][:n_bkg_1]\n",
    "                f_out[key][n_sig_1+n_bkg_1:n_sig_1+n_bkg_1+n_sig_2] = f_sig[key][:][SB_range_s][:n_sig_2]\n",
    "                f_out[key][n_sig_1+n_bkg_1+n_sig_2:] = f_bkg[key][:][SB_range_b][:n_bkg_2]\n",
    "\n",
    "        f_out['EVENT/signal'][:n_sig_1+n_bkg_1] = 1\n",
    "        f_out['EVENT/signal'][n_sig_1+n_bkg_1:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original mix sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data process flow\n",
    "# background.h5 merged from background_03.h5 background_04.h5 files\n",
    "sig_path = './Sample/HVmodel/data/split_val/signal.h5'\n",
    "bkg_path = './Sample/HVmodel/data/split_val/background.h5'\n",
    "\n",
    "for i in range(11):\n",
    "    sensitivity = i\n",
    "    n_SR_S = sensitivity * np.sqrt(n_SR_B)\n",
    "    n_SB_S = n_SR_S * results_s['cutflow_number']['Sideband region'] / results_s['cutflow_number']['Signal region']\n",
    "\n",
    "    n_sig_1, n_sig_2, n_bkg_1, n_bkg_2 = int(n_SR_S * r_train), int(n_SB_S * r_train), int(n_SR_B * r_train), int(n_SB_B * r_train)\n",
    "    output_path = f'./Sample/HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    create_mix_sample_from_numbers(sig_path, bkg_path, n_sig_1, n_sig_2, n_bkg_1, n_bkg_2, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Luminosity $\\times 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_path = './Sample/HVmodel/data/split_val/signal.h5'\n",
    "bkg_path = './Sample/HVmodel/data/split_val/background.h5'\n",
    "\n",
    "for i in range(11):\n",
    "    sensitivity = i\n",
    "    n_SR_S = sensitivity * np.sqrt(n_SR_B)\n",
    "    n_SB_S = n_SR_S * results_s['cutflow_number']['Sideband region'] / results_s['cutflow_number']['Signal region']\n",
    "\n",
    "    n_sig_1, n_sig_2, n_bkg_1, n_bkg_2 = int(n_SR_S * r_train), int(n_SB_S * r_train), int(n_SR_B * r_train), int(n_SB_B * r_train)\n",
    "    output_path = f'./Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_x2.h5'\n",
    "    create_mix_sample_from_numbers(sig_path, bkg_path, n_sig_1, n_sig_2, n_bkg_1, n_bkg_2, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_path = './Sample/HVmodel/data/split_val/signal.h5'\n",
    "bkg_path = './Sample/HVmodel/data/split_val/background.h5'\n",
    "\n",
    "for i in range(1):\n",
    "    sensitivity = i\n",
    "    n_SR_S = sensitivity * np.sqrt(n_SR_B)\n",
    "    n_SB_S = n_SR_S * results_s['cutflow_number']['Sideband region'] / results_s['cutflow_number']['Signal region']\n",
    "\n",
    "    n_sig_1, n_sig_2, n_bkg_1, n_bkg_2 = int(n_SR_S * r_train), int(n_SB_S * r_train), int(n_SR_B * r_train), int(n_SB_B * r_train)\n",
    "    output_path = f'./Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_x4.h5'\n",
    "    create_mix_sample_from_numbers(sig_path, bkg_path, n_sig_1, n_sig_2, n_bkg_1, n_bkg_2, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_path = './Sample/HVmodel/data/split_val/signal-val.h5'\n",
    "bkg_path = './Sample/HVmodel/data/split_val/background-val.h5'\n",
    "\n",
    "for i in range(11):\n",
    "    sensitivity = i\n",
    "    n_SR_S = sensitivity * np.sqrt(n_SR_B)\n",
    "    n_SB_S = n_SR_S * results_s['cutflow_number']['Sideband region'] / results_s['cutflow_number']['Signal region']\n",
    "\n",
    "    n_sig_1, n_sig_2, n_bkg_1, n_bkg_2 = int(n_SR_S * r_val), int(n_SB_S * r_val), int(n_SR_B * r_val), int(n_SB_B * r_val)\n",
    "    output_path = f'./Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val.h5'\n",
    "    create_mix_sample_from_numbers(sig_path, bkg_path, n_sig_1, n_sig_2, n_bkg_1, n_bkg_2, output_path, SRSB_region=[4400, 4700, 5500, 5800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Luminosity $\\times 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_path = './Sample/HVmodel/data/split_val/signal-val.h5'\n",
    "bkg_path = './Sample/HVmodel/data/split_val/background-val.h5'\n",
    "\n",
    "for i in range(11):\n",
    "    sensitivity = i\n",
    "    n_SR_S = sensitivity * np.sqrt(n_SR_B)\n",
    "    n_SB_S = n_SR_S * results_s['cutflow_number']['Sideband region'] / results_s['cutflow_number']['Signal region']\n",
    "\n",
    "    n_sig_1, n_sig_2, n_bkg_1, n_bkg_2 = int(n_SR_S * r_val), int(n_SB_S * r_val), int(n_SR_B * r_val), int(n_SB_B * r_val)\n",
    "    output_path = f'./Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_x2_val.h5'\n",
    "    create_mix_sample_from_numbers(sig_path, bkg_path, n_sig_1, n_sig_2, n_bkg_1, n_bkg_2, output_path, SRSB_region=[4400, 4700, 5500, 5800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Testing sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_path, bkg_path  = './Sample/HVmodel/data/split_val/signal-test.h5', './Sample/HVmodel/data/split_val/background-test.h5'\n",
    "n_sig_1, n_bkg_1 = 10000, 10000\n",
    "nevent = n_sig_1 + n_bkg_1\n",
    "\n",
    "with h5py.File('./Sample/HVmodel/data/split_val/mix_sample_test.h5', 'w') as f_out:\n",
    "    \n",
    "    MAX_JETS = 300 \n",
    "    create_dataset(f_out, nevent, MAX_JETS)\n",
    "\n",
    "    keys = get_dataset_keys(f_out)\n",
    "    with h5py.File(sig_path, 'r') as f_sig, h5py.File(bkg_path, 'r') as f_bkg:  \n",
    "        mjj_s = f_sig['EVENT/Mjj'][:]\n",
    "        mjj_b = f_bkg['EVENT/Mjj'][:]\n",
    "        SR_range_s = (mjj_s > 4700) & (mjj_s < 5500)\n",
    "        SR_range_b = (mjj_b > 4700) & (mjj_b < 5500)\n",
    "\n",
    "        for key in keys:\n",
    "            f_out[key][:n_sig_1] = f_sig[key][:][SR_range_s][:n_sig_1]\n",
    "            f_out[key][n_sig_1:] = f_bkg[key][:][SR_range_b][:n_bkg_1]\n",
    "\n",
    "    f_out['EVENT/signal'][:n_sig_1] = 1\n",
    "    f_out['EVENT/signal'][n_sig_1:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_path, bkg_path  = './Sample/HVmodel/data/new/signal-test-2.h5', './Sample/HVmodel/data/new/background-test-2.h5'\n",
    "n_sig_1, n_bkg_1 = 10000, 10000\n",
    "nevent = n_sig_1 + n_bkg_1\n",
    "\n",
    "with h5py.File('./Sample/HVmodel/data/new/mix_sample_testing-2.h5', 'w') as f_out:\n",
    "    \n",
    "    MAX_JETS = 300 \n",
    "    create_dataset(f_out, nevent, MAX_JETS)\n",
    "\n",
    "    keys = get_dataset_keys(f_out)\n",
    "    with h5py.File(sig_path, 'r') as f_sig, h5py.File(bkg_path, 'r') as f_bkg:  \n",
    "        mjj_s = f_sig['EVENT/Mjj'][:]\n",
    "        mjj_b = f_bkg['EVENT/Mjj'][:]\n",
    "        SR_range_s = (mjj_s > 4700) & (mjj_s < 5500)\n",
    "        SR_range_b = (mjj_b > 4700) & (mjj_b < 5500)\n",
    "\n",
    "        for key in keys:\n",
    "            f_out[key][:n_sig_1] = f_sig[key][:][SR_range_s][:n_sig_1]\n",
    "            f_out[key][n_sig_1:] = f_bkg[key][:][SR_range_b][:n_bkg_1]\n",
    "\n",
    "    f_out['EVENT/signal'][:n_sig_1] = 1\n",
    "    f_out['EVENT/signal'][n_sig_1:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Sample/physical_augmentation_h5.ipynb\n",
    "\n",
    "Sample/rotate_jet.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jet rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_0.0.h5 ./HVmodel/data/rotate_jet/mix_sample_0.0_jet_aug_3_75x75.h5 3 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/rotate_jet/mix_sample_1.0_jet_aug_3_75x75.h5 3 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_2.0.h5 ./HVmodel/data/rotate_jet/mix_sample_2.0_jet_aug_3_75x75.h5 3 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/rotate_jet/mix_sample_3.0_jet_aug_3_75x75.h5 3 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_4.0.h5 ./HVmodel/data/rotate_jet/mix_sample_4.0_jet_aug_3_75x75.h5 3 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_5.0.h5 ./HVmodel/data/rotate_jet/mix_sample_5.0_jet_aug_3_75x75.h5 3 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_6.0.h5 ./HVmodel/data/rotate_jet/mix_sample_6.0_jet_aug_3_75x75.h5 3 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_7.0.h5 ./HVmodel/data/rotate_jet/mix_sample_7.0_jet_aug_3_75x75.h5 3 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_8.0.h5 ./HVmodel/data/rotate_jet/mix_sample_8.0_jet_aug_3_75x75.h5 3 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_9.0.h5 ./HVmodel/data/rotate_jet/mix_sample_9.0_jet_aug_3_75x75.h5 3 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_10.0.h5 ./HVmodel/data/rotate_jet/mix_sample_10.0_jet_aug_3_75x75.h5 3 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/rotate_jet/mix_sample_{i:.1f}_jet_aug_3_75x75.h5'\n",
    "    n = 3\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python rotate_jet.py {h5_file} {output_path} {n} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_0.0.h5 ./HVmodel/data/rotate_jet/mix_sample_0.0_jet_aug_5_75x75.h5 5 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/rotate_jet/mix_sample_1.0_jet_aug_5_75x75.h5 5 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_2.0.h5 ./HVmodel/data/rotate_jet/mix_sample_2.0_jet_aug_5_75x75.h5 5 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/rotate_jet/mix_sample_3.0_jet_aug_5_75x75.h5 5 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_4.0.h5 ./HVmodel/data/rotate_jet/mix_sample_4.0_jet_aug_5_75x75.h5 5 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_5.0.h5 ./HVmodel/data/rotate_jet/mix_sample_5.0_jet_aug_5_75x75.h5 5 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_6.0.h5 ./HVmodel/data/rotate_jet/mix_sample_6.0_jet_aug_5_75x75.h5 5 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_7.0.h5 ./HVmodel/data/rotate_jet/mix_sample_7.0_jet_aug_5_75x75.h5 5 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_8.0.h5 ./HVmodel/data/rotate_jet/mix_sample_8.0_jet_aug_5_75x75.h5 5 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_9.0.h5 ./HVmodel/data/rotate_jet/mix_sample_9.0_jet_aug_5_75x75.h5 5 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_10.0.h5 ./HVmodel/data/rotate_jet/mix_sample_10.0_jet_aug_5_75x75.h5 5 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/rotate_jet/mix_sample_{i:.1f}_jet_aug_5_75x75.h5'\n",
    "    n = 5\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python rotate_jet.py {h5_file} {output_path} {n} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_0.0.h5 ./HVmodel/data/jet_rotation/mix_sample_0.0_jet_aug_1_25x25.h5 1 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_1_25x25.h5 1 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_2.0.h5 ./HVmodel/data/jet_rotation/mix_sample_2.0_jet_aug_1_25x25.h5 1 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_1_25x25.h5 1 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_4.0.h5 ./HVmodel/data/jet_rotation/mix_sample_4.0_jet_aug_1_25x25.h5 1 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_5.0.h5 ./HVmodel/data/jet_rotation/mix_sample_5.0_jet_aug_1_25x25.h5 1 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_6.0.h5 ./HVmodel/data/jet_rotation/mix_sample_6.0_jet_aug_1_25x25.h5 1 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_7.0.h5 ./HVmodel/data/jet_rotation/mix_sample_7.0_jet_aug_1_25x25.h5 1 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_8.0.h5 ./HVmodel/data/jet_rotation/mix_sample_8.0_jet_aug_1_25x25.h5 1 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_9.0.h5 ./HVmodel/data/jet_rotation/mix_sample_9.0_jet_aug_1_25x25.h5 1 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_10.0.h5 ./HVmodel/data/jet_rotation/mix_sample_10.0_jet_aug_1_25x25.h5 1 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_1_25x25.h5'\n",
    "    n = 1\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python rotate_jet.py {h5_file} {output_path} {n} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_0.0.h5 ./HVmodel/data/jet_rotation/mix_sample_0.0_jet_aug_3_25x25.h5 3 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_3_25x25.h5 3 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_2.0.h5 ./HVmodel/data/jet_rotation/mix_sample_2.0_jet_aug_3_25x25.h5 3 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_3_25x25.h5 3 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_4.0.h5 ./HVmodel/data/jet_rotation/mix_sample_4.0_jet_aug_3_25x25.h5 3 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_5.0.h5 ./HVmodel/data/jet_rotation/mix_sample_5.0_jet_aug_3_25x25.h5 3 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_6.0.h5 ./HVmodel/data/jet_rotation/mix_sample_6.0_jet_aug_3_25x25.h5 3 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_7.0.h5 ./HVmodel/data/jet_rotation/mix_sample_7.0_jet_aug_3_25x25.h5 3 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_8.0.h5 ./HVmodel/data/jet_rotation/mix_sample_8.0_jet_aug_3_25x25.h5 3 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_9.0.h5 ./HVmodel/data/jet_rotation/mix_sample_9.0_jet_aug_3_25x25.h5 3 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_10.0.h5 ./HVmodel/data/jet_rotation/mix_sample_10.0_jet_aug_3_25x25.h5 3 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_3_25x25.h5'\n",
    "    n = 3\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python rotate_jet.py {h5_file} {output_path} {n} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_0.0.h5 ./HVmodel/data/jet_rotation/mix_sample_0.0_jet_aug_5_25x25.h5 5 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_5_25x25.h5 5 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_2.0.h5 ./HVmodel/data/jet_rotation/mix_sample_2.0_jet_aug_5_25x25.h5 5 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_5_25x25.h5 5 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_4.0.h5 ./HVmodel/data/jet_rotation/mix_sample_4.0_jet_aug_5_25x25.h5 5 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_5.0.h5 ./HVmodel/data/jet_rotation/mix_sample_5.0_jet_aug_5_25x25.h5 5 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_6.0.h5 ./HVmodel/data/jet_rotation/mix_sample_6.0_jet_aug_5_25x25.h5 5 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_7.0.h5 ./HVmodel/data/jet_rotation/mix_sample_7.0_jet_aug_5_25x25.h5 5 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_8.0.h5 ./HVmodel/data/jet_rotation/mix_sample_8.0_jet_aug_5_25x25.h5 5 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_9.0.h5 ./HVmodel/data/jet_rotation/mix_sample_9.0_jet_aug_5_25x25.h5 5 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_10.0.h5 ./HVmodel/data/jet_rotation/mix_sample_10.0_jet_aug_5_25x25.h5 5 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_5_25x25.h5'\n",
    "    n = 5\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python rotate_jet.py {h5_file} {output_path} {n} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Larger sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_7_75x75.h5 7 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_10_75x75.h5 10 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_15_75x75.h5 15 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_22_75x75.h5 22 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_33_75x75.h5 33 75 &\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "for n in [7, 10, 15, 22, 33]:\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_{n}_75x75.h5'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python rotate_jet.py {h5_file} {output_path} {n} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_7_25x25.h5 7 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_10_25x25.h5 10 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_15_25x25.h5 15 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_22_25x25.h5 22 25 &\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "for n in [7, 10, 15, 22]:\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_{n}_25x25.h5'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python rotate_jet.py {h5_file} {output_path} {n} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_7_75x75.h5 7 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_10_75x75.h5 10 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_15_75x75.h5 15 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_22_75x75.h5 22 75 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_33_75x75.h5 33 75 &\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for n in [7, 10, 15, 22, 33]:\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_{n}_75x75.h5'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python rotate_jet.py {h5_file} {output_path} {n} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_7_25x25.h5 7 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_10_25x25.h5 10 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_15_25x25.h5 15 25 &\n",
      "python rotate_jet.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_22_25x25.h5 22 25 &\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for n in [7, 10, 15, 22]:\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_{n}_25x25.h5'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python rotate_jet.py {h5_file} {output_path} {n} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $p_\\text{T}$ smearing + jet rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_0.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_0.0_aug_1_25x25.h5 1 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_1.0_aug_1_25x25.h5 1 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_2.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_2.0_aug_1_25x25.h5 1 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_3.0_aug_1_25x25.h5 1 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_4.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_4.0_aug_1_25x25.h5 1 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_5.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_5.0_aug_1_25x25.h5 1 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_6.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_6.0_aug_1_25x25.h5 1 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_7.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_7.0_aug_1_25x25.h5 1 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_8.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_8.0_aug_1_25x25.h5 1 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_9.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_9.0_aug_1_25x25.h5 1 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_10.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_10.0_aug_1_25x25.h5 1 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    n = 1\n",
    "    res = 25\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_{i:.1f}_aug_{n}_{res}x{res}.h5'\n",
    "\n",
    "    cmd = f'python pT_smearing_jet_rotation.py {h5_file} {output_path} {n} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_0.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_0.0_aug_3_25x25.h5 3 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_1.0_aug_3_25x25.h5 3 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_2.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_2.0_aug_3_25x25.h5 3 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_3.0_aug_3_25x25.h5 3 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_4.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_4.0_aug_3_25x25.h5 3 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_5.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_5.0_aug_3_25x25.h5 3 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_6.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_6.0_aug_3_25x25.h5 3 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_7.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_7.0_aug_3_25x25.h5 3 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_8.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_8.0_aug_3_25x25.h5 3 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_9.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_9.0_aug_3_25x25.h5 3 25 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_10.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_10.0_aug_3_25x25.h5 3 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    n = 3\n",
    "    res = 25\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_{i:.1f}_aug_{n}_{res}x{res}.h5'\n",
    "\n",
    "    cmd = f'python pT_smearing_jet_rotation.py {h5_file} {output_path} {n} {res} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_0.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_0.0_aug_3_75x75.h5 3 75 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_1.0_aug_3_75x75.h5 3 75 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_2.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_2.0_aug_3_75x75.h5 3 75 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_3.0_aug_3_75x75.h5 3 75 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_4.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_4.0_aug_3_75x75.h5 3 75 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_5.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_5.0_aug_3_75x75.h5 3 75 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_6.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_6.0_aug_3_75x75.h5 3 75 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_7.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_7.0_aug_3_75x75.h5 3 75 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_8.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_8.0_aug_3_75x75.h5 3 75 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_9.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_9.0_aug_3_75x75.h5 3 75 &\n",
      "python pT_smearing_jet_rotation.py ./HVmodel/data/split_val/mix_sample_10.0.h5 ./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_10.0_aug_3_75x75.h5 3 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    n = 3\n",
    "    res = 75\n",
    "    h5_file = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_{i:.1f}_aug_{n}_{res}x{res}.h5'\n",
    "\n",
    "    cmd = f'python pT_smearing_jet_rotation.py {h5_file} {output_path} {n} {res} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From h5 to npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution $75 \\times 75$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original mix sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0.h5 ./HVmodel/data/split_val/mix_sample_0.0_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/split_val/mix_sample_1.0_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0.h5 ./HVmodel/data/split_val/mix_sample_2.0_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/split_val/mix_sample_3.0_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0.h5 ./HVmodel/data/split_val/mix_sample_4.0_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0.h5 ./HVmodel/data/split_val/mix_sample_5.0_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0.h5 ./HVmodel/data/split_val/mix_sample_6.0_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0.h5 ./HVmodel/data/split_val/mix_sample_7.0_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0.h5 ./HVmodel/data/split_val/mix_sample_8.0_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0.h5 ./HVmodel/data/split_val/mix_sample_9.0_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0.h5 ./HVmodel/data/split_val/mix_sample_10.0_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_val.h5 ./HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_val.h5 ./HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_val.h5 ./HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_val.h5 ./HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_val.h5 ./HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_val.h5 ./HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_val.h5 ./HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_val.h5 ./HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_val.h5 ./HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_val.h5 ./HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_val.h5 ./HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_val.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_test.h5 ./HVmodel/data/split_val/mix_sample_test_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "h5_path = f'./HVmodel/data/split_val/mix_sample_test.h5'\n",
    "output_path = f'./HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "resolution = 75\n",
    "\n",
    "cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy: +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_0.0_copy_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_1.0_copy_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_2.0_copy_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_3.0_copy_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_4.0_copy_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_5.0_copy_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_6.0_copy_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_7.0_copy_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_8.0_copy_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_9.0_copy_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_10.0_copy_1_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_copy_1.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_copy_1_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\eta-\\phi$ augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_0.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_1.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_2.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_3.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_4.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_5.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_6.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_7.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_8.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_9.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_10.0_aug_1_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_aug_1.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_aug_1_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_0.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_0.0_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_1.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_1.0_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_2.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_2.0_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_3.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_3.0_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_4.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_4.0_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_5.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_5.0_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_6.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_6.0_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_7.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_7.0_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_8.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_8.0_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_9.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_9.0_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_smearing/mix_sample_10.0_aug_3.h5 ./HVmodel/data/eta_phi_smearing/75x75/mix_sample_10.0_aug_3_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/eta_phi_smearing/mix_sample_{i:.1f}_aug_3.h5'\n",
    "    output_path = f'./HVmodel/data/eta_phi_smearing/75x75/mix_sample_{i:.1f}_aug_3_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Luminosity: $\\times 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_x2.h5 ./HVmodel/data/split_val/mix_sample_0.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_x2.h5 ./HVmodel/data/split_val/mix_sample_1.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_x2.h5 ./HVmodel/data/split_val/mix_sample_2.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_x2.h5 ./HVmodel/data/split_val/mix_sample_3.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_x2.h5 ./HVmodel/data/split_val/mix_sample_4.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_x2.h5 ./HVmodel/data/split_val/mix_sample_5.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_x2.h5 ./HVmodel/data/split_val/mix_sample_6.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_x2.h5 ./HVmodel/data/split_val/mix_sample_7.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_x2.h5 ./HVmodel/data/split_val/mix_sample_8.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_x2.h5 ./HVmodel/data/split_val/mix_sample_9.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_x2.h5 ./HVmodel/data/split_val/mix_sample_10.0_x2_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_0.0_x2_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_1.0_x2_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_2.0_x2_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_3.0_x2_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_4.0_x2_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_5.0_x2_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_6.0_x2_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_7.0_x2_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_8.0_x2_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_9.0_x2_val_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_10.0_x2_val_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_x2.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_x2_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)\n",
    "\n",
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_x2_val.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_x2_val_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smearing scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_0.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_0.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_1.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_1.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_2.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_2.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_3.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_3.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_4.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_4.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_5.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_5.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_6.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_6.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_7.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_7.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_8.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_8.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_9.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_9.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_10.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_10.0_aug_1_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/smearing_scale_02/mix_sample_{i:.1f}_aug_1.h5'\n",
    "    output_path = f'./HVmodel/data/smearing_scale_02/mix_sample_{i:.1f}_aug_1_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_0.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_0.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_1.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_1.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_2.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_2.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_3.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_3.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_4.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_4.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_5.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_5.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_6.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_6.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_7.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_7.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_8.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_8.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_9.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_9.0_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_10.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_10.0_aug_1_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/smearing_scale_05/mix_sample_{i:.1f}_aug_1.h5'\n",
    "    output_path = f'./HVmodel/data/smearing_scale_05/mix_sample_{i:.1f}_aug_1_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $p_{\\text{T}}$ augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_0.0_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_1.0_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_2.0_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_3.0_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_4.0_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_5.0_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_6.0_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_7.0_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_8.0_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_9.0_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_10.0_pt_aug_1_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_1.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_1_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_0.0_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_1.0_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_2.0_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_3.0_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_4.0_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_5.0_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_6.0_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_7.0_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_8.0_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_9.0_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_10.0_pt_aug_3_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_3.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_3_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_0.0_pt_aug_5_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_1.0_pt_aug_5_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_2.0_pt_aug_5_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_3.0_pt_aug_5_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_4.0_pt_aug_5_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_5.0_pt_aug_5_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_6.0_pt_aug_5_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_7.0_pt_aug_5_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_8.0_pt_aug_5_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_9.0_pt_aug_5_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_pt_aug_5.h5 ./HVmodel/data/split_val/mix_sample_10.0_pt_aug_5_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_5.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_5_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\eta-\\phi$ augmentation + $p_{\\text{T}}$ augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_0.0_eta_phi_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_1.0_eta_phi_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_2.0_eta_phi_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_3.0_eta_phi_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_4.0_eta_phi_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_5.0_eta_phi_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_6.0_eta_phi_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_7.0_eta_phi_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_8.0_eta_phi_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_9.0_eta_phi_pt_aug_1_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_10.0_eta_phi_pt_aug_1_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_eta_phi_pt_aug_1.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_eta_phi_pt_aug_1_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_0.0_eta_phi_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_1.0_eta_phi_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_2.0_eta_phi_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_3.0_eta_phi_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_4.0_eta_phi_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_5.0_eta_phi_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_6.0_eta_phi_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_7.0_eta_phi_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_8.0_eta_phi_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_9.0_eta_phi_pt_aug_3_75x75.npy 75 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/split_val/mix_sample_10.0_eta_phi_pt_aug_3_75x75.npy 75 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_eta_phi_pt_aug_3.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_eta_phi_pt_aug_3_75x75.npy'\n",
    "    resolution = 75\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution $25 \\times 25$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original mix sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0.h5 ./HVmodel/data/split_val/mix_sample_0.0_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0.h5 ./HVmodel/data/split_val/mix_sample_1.0_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0.h5 ./HVmodel/data/split_val/mix_sample_2.0_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0.h5 ./HVmodel/data/split_val/mix_sample_3.0_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0.h5 ./HVmodel/data/split_val/mix_sample_4.0_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0.h5 ./HVmodel/data/split_val/mix_sample_5.0_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0.h5 ./HVmodel/data/split_val/mix_sample_6.0_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0.h5 ./HVmodel/data/split_val/mix_sample_7.0_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0.h5 ./HVmodel/data/split_val/mix_sample_8.0_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0.h5 ./HVmodel/data/split_val/mix_sample_9.0_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0.h5 ./HVmodel/data/split_val/mix_sample_10.0_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_val.h5 ./HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_val.h5 ./HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_val.h5 ./HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_val.h5 ./HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_val.h5 ./HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_val.h5 ./HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_val.h5 ./HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_val.h5 ./HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_val.h5 ./HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_val.h5 ./HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_val.h5 ./HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_val.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_test.h5 ./HVmodel/data/split_val/mix_sample_test_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "h5_path = f'./HVmodel/data/split_val/mix_sample_test.h5'\n",
    "output_path = f'./HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "resolution = 25\n",
    "\n",
    "cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy: +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_0.0_copy_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_1.0_copy_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_2.0_copy_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_3.0_copy_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_4.0_copy_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_5.0_copy_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_6.0_copy_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_7.0_copy_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_8.0_copy_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_9.0_copy_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_copy_1.h5 ./HVmodel/data/split_val/mix_sample_10.0_copy_1_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_copy_1.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_copy_1_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Luminosity: $\\times 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_x2.h5 ./HVmodel/data/split_val/mix_sample_0.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_x2.h5 ./HVmodel/data/split_val/mix_sample_1.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_x2.h5 ./HVmodel/data/split_val/mix_sample_2.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_x2.h5 ./HVmodel/data/split_val/mix_sample_3.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_x2.h5 ./HVmodel/data/split_val/mix_sample_4.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_x2.h5 ./HVmodel/data/split_val/mix_sample_5.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_x2.h5 ./HVmodel/data/split_val/mix_sample_6.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_x2.h5 ./HVmodel/data/split_val/mix_sample_7.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_x2.h5 ./HVmodel/data/split_val/mix_sample_8.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_x2.h5 ./HVmodel/data/split_val/mix_sample_9.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_x2.h5 ./HVmodel/data/split_val/mix_sample_10.0_x2_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_0.0_x2_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_1.0_x2_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_2.0_x2_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_3.0_x2_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_4.0_x2_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_5.0_x2_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_6.0_x2_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_7.0_x2_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_8.0_x2_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_9.0_x2_val_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_x2_val.h5 ./HVmodel/data/split_val/mix_sample_10.0_x2_val_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_x2.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_x2_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)\n",
    "    \n",
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_x2_val.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_x2_val_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\eta-\\phi$ augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_0.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_1.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_2.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_3.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_4.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_5.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_6.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_7.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_8.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_9.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_aug_1.h5 ./HVmodel/data/split_val/mix_sample_10.0_aug_1_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_aug_1.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_aug_1_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_0.0_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_1.0_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_2.0_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_3.0_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_4.0_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_5.0_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_6.0_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_7.0_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_8.0_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_9.0_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_aug_3.h5 ./HVmodel/data/split_val/mix_sample_10.0_aug_3_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_aug_3.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_aug_3_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smearing scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_0.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_0.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_1.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_1.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_2.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_2.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_3.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_3.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_4.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_4.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_5.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_5.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_6.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_6.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_7.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_7.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_8.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_8.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_9.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_9.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_02/mix_sample_10.0_aug_1.h5 ./HVmodel/data/smearing_scale_02/mix_sample_10.0_aug_1_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/smearing_scale_02/mix_sample_{i:.1f}_aug_1.h5'\n",
    "    output_path = f'./HVmodel/data/smearing_scale_02/mix_sample_{i:.1f}_aug_1_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_0.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_0.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_1.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_1.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_2.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_2.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_3.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_3.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_4.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_4.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_5.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_5.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_6.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_6.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_7.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_7.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_8.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_8.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_9.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_9.0_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/smearing_scale_05/mix_sample_10.0_aug_1.h5 ./HVmodel/data/smearing_scale_05/mix_sample_10.0_aug_1_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/smearing_scale_05/mix_sample_{i:.1f}_aug_1.h5'\n",
    "    output_path = f'./HVmodel/data/smearing_scale_05/mix_sample_{i:.1f}_aug_1_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $p_{\\text{T}}$ augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_0.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_0.0_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_1.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_1.0_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_2.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_2.0_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_3.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_3.0_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_4.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_4.0_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_5.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_5.0_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_6.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_6.0_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_7.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_7.0_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_8.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_8.0_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_9.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_9.0_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/split_val/mix_sample_10.0_pt_aug_1.h5 ./HVmodel/data/split_val/mix_sample_10.0_pt_aug_1_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_1.h5'\n",
    "    output_path = f'./HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_1_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_0.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_0.0_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_1.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_1.0_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_2.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_2.0_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_3.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_3.0_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_4.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_4.0_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_5.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_5.0_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_6.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_6.0_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_7.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_7.0_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_8.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_8.0_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_9.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_9.0_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_10.0_pt_aug_3.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_10.0_pt_aug_3_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/pt_smearing/mix_sample_{i:.1f}_pt_aug_3.h5'\n",
    "    output_path = f'./HVmodel/data/pt_smearing/25x25/mix_sample_{i:.1f}_pt_aug_3_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_0.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_0.0_pt_aug_5_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_1.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_1.0_pt_aug_5_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_2.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_2.0_pt_aug_5_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_3.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_3.0_pt_aug_5_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_4.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_4.0_pt_aug_5_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_5.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_5.0_pt_aug_5_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_6.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_6.0_pt_aug_5_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_7.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_7.0_pt_aug_5_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_8.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_8.0_pt_aug_5_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_9.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_9.0_pt_aug_5_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/pt_smearing/mix_sample_10.0_pt_aug_5.h5 ./HVmodel/data/pt_smearing/25x25/mix_sample_10.0_pt_aug_5_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/pt_smearing/mix_sample_{i:.1f}_pt_aug_5.h5'\n",
    "    output_path = f'./HVmodel/data/pt_smearing/25x25/mix_sample_{i:.1f}_pt_aug_5_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\eta-\\phi$ augmentation + $p_{\\text{T}}$ augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_0.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_0.0_eta_phi_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_1.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_1.0_eta_phi_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_2.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_2.0_eta_phi_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_3.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_3.0_eta_phi_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_4.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_4.0_eta_phi_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_5.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_5.0_eta_phi_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_6.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_6.0_eta_phi_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_7.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_7.0_eta_phi_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_8.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_8.0_eta_phi_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_9.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_9.0_eta_phi_pt_aug_1_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_10.0_eta_phi_pt_aug_1.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_10.0_eta_phi_pt_aug_1_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/eta_phi_pt_smearing/mix_sample_{i:.1f}_eta_phi_pt_aug_1.h5'\n",
    "    output_path = f'./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_{i:.1f}_eta_phi_pt_aug_1_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_0.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_0.0_eta_phi_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_1.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_1.0_eta_phi_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_2.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_2.0_eta_phi_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_3.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_3.0_eta_phi_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_4.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_4.0_eta_phi_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_5.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_5.0_eta_phi_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_6.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_6.0_eta_phi_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_7.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_7.0_eta_phi_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_8.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_8.0_eta_phi_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_9.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_9.0_eta_phi_pt_aug_3_25x25.npy 25 &\n",
      "python from_h5_to_npy.py ./HVmodel/data/eta_phi_pt_smearing/mix_sample_10.0_eta_phi_pt_aug_3.h5 ./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_10.0_eta_phi_pt_aug_3_25x25.npy 25 &\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    h5_path = f'./HVmodel/data/eta_phi_pt_smearing/mix_sample_{i:.1f}_eta_phi_pt_aug_3.h5'\n",
    "    output_path = f'./HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_{i:.1f}_eta_phi_pt_aug_3_25x25.npy'\n",
    "    resolution = 25\n",
    "\n",
    "    cmd = f'python from_h5_to_npy.py {h5_path} {output_path} {resolution} &'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_25x25.npy SB_0.0_2_image_25x25_split_val \"Sensitivity: 0.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_25x25.npy SB_1.0_2_image_25x25_split_val \"Sensitivity: 1.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_25x25.npy SB_2.0_2_image_25x25_split_val \"Sensitivity: 2.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_25x25.npy SB_3.0_2_image_25x25_split_val \"Sensitivity: 3.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_25x25.npy SB_4.0_2_image_25x25_split_val \"Sensitivity: 4.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_25x25.npy SB_5.0_2_image_25x25_split_val \"Sensitivity: 5.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_25x25.npy SB_6.0_2_image_25x25_split_val \"Sensitivity: 6.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_25x25.npy SB_7.0_2_image_25x25_split_val \"Sensitivity: 7.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_25x25.npy SB_8.0_2_image_25x25_split_val \"Sensitivity: 8.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_25x25.npy SB_9.0_2_image_25x25_split_val \"Sensitivity: 9.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_25x25.npy SB_10.0_2_image_25x25_split_val \"Sensitivity: 10.0, Resolution: 25x25, SB region: 4400-4700, 5500-5800\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_2_image_25x25_split_val'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, SB region: 4400-4700, 5500-5800'\n",
    "    cmd = f'python train_CNN.py {train_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_25x25_copy_1.npy SB_0.0_copy_1_2_image_25x25_split_val \"Sensitivity: 0.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_25x25_copy_1.npy SB_1.0_copy_1_2_image_25x25_split_val \"Sensitivity: 1.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_25x25_copy_1.npy SB_2.0_copy_1_2_image_25x25_split_val \"Sensitivity: 2.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_25x25_copy_1.npy SB_3.0_copy_1_2_image_25x25_split_val \"Sensitivity: 3.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_25x25_copy_1.npy SB_4.0_copy_1_2_image_25x25_split_val \"Sensitivity: 4.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_25x25_copy_1.npy SB_5.0_copy_1_2_image_25x25_split_val \"Sensitivity: 5.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_25x25_copy_1.npy SB_6.0_copy_1_2_image_25x25_split_val \"Sensitivity: 6.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_25x25_copy_1.npy SB_7.0_copy_1_2_image_25x25_split_val \"Sensitivity: 7.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_25x25_copy_1.npy SB_8.0_copy_1_2_image_25x25_split_val \"Sensitivity: 8.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_25x25_copy_1.npy SB_9.0_copy_1_2_image_25x25_split_val \"Sensitivity: 9.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_25x25_copy_1.npy SB_10.0_copy_1_2_image_25x25_split_val \"Sensitivity: 10.0, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_25x25_copy_1.npy'\n",
    "    model_name = f'SB_{i:.1f}_copy_1_2_image_25x25_split_val'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Copy: 1, SB region: 4400-4700, 5500-5800'\n",
    "    cmd = f'python train_CNN.py {train_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New data process flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original mix dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_75x75 \"Sensitivity: 0.0, Resolution: 75x75\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_75x75 \"Sensitivity: 1.0, Resolution: 75x75\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_75x75 \"Sensitivity: 2.0, Resolution: 75x75\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_75x75 \"Sensitivity: 3.0, Resolution: 75x75\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_75x75 \"Sensitivity: 4.0, Resolution: 75x75\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_75x75 \"Sensitivity: 5.0, Resolution: 75x75\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_75x75 \"Sensitivity: 6.0, Resolution: 75x75\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_75x75 \"Sensitivity: 7.0, Resolution: 75x75\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_75x75 \"Sensitivity: 8.0, Resolution: 75x75\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_75x75 \"Sensitivity: 9.0, Resolution: 75x75\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_75x75 \"Sensitivity: 10.0, Resolution: 75x75\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_25x25 \"Sensitivity: 0.0, Resolution: 25x25\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_25x25 \"Sensitivity: 1.0, Resolution: 25x25\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_25x25 \"Sensitivity: 2.0, Resolution: 25x25\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_25x25 \"Sensitivity: 3.0, Resolution: 25x25\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_25x25 \"Sensitivity: 4.0, Resolution: 25x25\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_25x25 \"Sensitivity: 5.0, Resolution: 25x25\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_25x25 \"Sensitivity: 6.0, Resolution: 25x25\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_25x25 \"Sensitivity: 7.0, Resolution: 25x25\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_25x25 \"Sensitivity: 8.0, Resolution: 25x25\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_25x25 \"Sensitivity: 9.0, Resolution: 25x25\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_25x25 \"Sensitivity: 10.0, Resolution: 25x25\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy: +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_copy_1_75x75 \"Sensitivity: 0.0, Resolution: 75x75, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_copy_1_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_copy_1_75x75 \"Sensitivity: 2.0, Resolution: 75x75, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_copy_1_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_copy_1_75x75 \"Sensitivity: 4.0, Resolution: 75x75, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_copy_1_75x75 \"Sensitivity: 5.0, Resolution: 75x75, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_copy_1_75x75 \"Sensitivity: 6.0, Resolution: 75x75, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_copy_1_75x75 \"Sensitivity: 7.0, Resolution: 75x75, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_copy_1_75x75 \"Sensitivity: 8.0, Resolution: 75x75, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_copy_1_75x75 \"Sensitivity: 9.0, Resolution: 75x75, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_copy_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_copy_1_75x75 \"Sensitivity: 10.0, Resolution: 75x75, Copy: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_copy_1_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_copy_1_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Copy: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_copy_1_25x25 \"Sensitivity: 0.0, Resolution: 25x25, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_copy_1_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_copy_1_25x25 \"Sensitivity: 2.0, Resolution: 25x25, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_copy_1_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_copy_1_25x25 \"Sensitivity: 4.0, Resolution: 25x25, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_copy_1_25x25 \"Sensitivity: 5.0, Resolution: 25x25, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_copy_1_25x25 \"Sensitivity: 6.0, Resolution: 25x25, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_copy_1_25x25 \"Sensitivity: 7.0, Resolution: 25x25, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_copy_1_25x25 \"Sensitivity: 8.0, Resolution: 25x25, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_copy_1_25x25 \"Sensitivity: 9.0, Resolution: 25x25, Copy: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_copy_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_copy_1_25x25 \"Sensitivity: 10.0, Resolution: 25x25, Copy: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_copy_1_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_copy_1_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Copy: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\eta-\\phi$ augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_aug_1_75x75 \"Sensitivity: 0.0, Resolution: 75x75, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_aug_1_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_aug_1_75x75 \"Sensitivity: 2.0, Resolution: 75x75, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_aug_1_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_aug_1_75x75 \"Sensitivity: 4.0, Resolution: 75x75, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_aug_1_75x75 \"Sensitivity: 5.0, Resolution: 75x75, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_aug_1_75x75 \"Sensitivity: 6.0, Resolution: 75x75, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_aug_1_75x75 \"Sensitivity: 7.0, Resolution: 75x75, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_aug_1_75x75 \"Sensitivity: 8.0, Resolution: 75x75, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_aug_1_75x75 \"Sensitivity: 9.0, Resolution: 75x75, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_aug_1_75x75 \"Sensitivity: 10.0, Resolution: 75x75, Augmentation: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_aug_1_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_aug_1_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Augmentation: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_aug_1_25x25 \"Sensitivity: 0.0, Resolution: 25x25, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_aug_1_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_aug_1_25x25 \"Sensitivity: 2.0, Resolution: 25x25, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_aug_1_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_aug_1_25x25 \"Sensitivity: 4.0, Resolution: 25x25, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_aug_1_25x25 \"Sensitivity: 5.0, Resolution: 25x25, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_aug_1_25x25 \"Sensitivity: 6.0, Resolution: 25x25, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_aug_1_25x25 \"Sensitivity: 7.0, Resolution: 25x25, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_aug_1_25x25 \"Sensitivity: 8.0, Resolution: 25x25, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_aug_1_25x25 \"Sensitivity: 9.0, Resolution: 25x25, Augmentation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_aug_1_25x25 \"Sensitivity: 10.0, Resolution: 25x25, Augmentation: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_aug_1_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_aug_1_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Augmentation: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_0.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_aug_3_75x75 \"Sensitivity: 0.0, Resolution: 75x75, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_1.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_aug_3_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_2.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_aug_3_75x75 \"Sensitivity: 2.0, Resolution: 75x75, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_3.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_aug_3_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_4.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_aug_3_75x75 \"Sensitivity: 4.0, Resolution: 75x75, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_5.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_aug_3_75x75 \"Sensitivity: 5.0, Resolution: 75x75, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_6.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_aug_3_75x75 \"Sensitivity: 6.0, Resolution: 75x75, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_7.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_aug_3_75x75 \"Sensitivity: 7.0, Resolution: 75x75, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_8.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_aug_3_75x75 \"Sensitivity: 8.0, Resolution: 75x75, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_9.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_aug_3_75x75 \"Sensitivity: 9.0, Resolution: 75x75, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_10.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_aug_3_75x75 \"Sensitivity: 10.0, Resolution: 75x75, Augmentation: +3\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/eta_phi_smearing/75x75/mix_sample_{i:.1f}_aug_3_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_aug_3_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Augmentation: +3'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_aug_3_25x25 \"Sensitivity: 0.0, Resolution: 25x25, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_aug_3_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_aug_3_25x25 \"Sensitivity: 2.0, Resolution: 25x25, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_aug_3_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_aug_3_25x25 \"Sensitivity: 4.0, Resolution: 25x25, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_aug_3_25x25 \"Sensitivity: 5.0, Resolution: 25x25, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_aug_3_25x25 \"Sensitivity: 6.0, Resolution: 25x25, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_aug_3_25x25 \"Sensitivity: 7.0, Resolution: 25x25, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_aug_3_25x25 \"Sensitivity: 8.0, Resolution: 25x25, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_aug_3_25x25 \"Sensitivity: 9.0, Resolution: 25x25, Augmentation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_aug_3_25x25 \"Sensitivity: 10.0, Resolution: 25x25, Augmentation: +3\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_aug_3_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_aug_3_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Augmentation: +3'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luminosity: $\\times 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_x2_75x75 \"Sensitivity: 0.0, Resolution: 75x75, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_x2_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_x2_75x75 \"Sensitivity: 2.0, Resolution: 75x75, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_x2_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_x2_75x75 \"Sensitivity: 4.0, Resolution: 75x75, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_x2_75x75 \"Sensitivity: 5.0, Resolution: 75x75, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_x2_75x75 \"Sensitivity: 6.0, Resolution: 75x75, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_x2_75x75 \"Sensitivity: 7.0, Resolution: 75x75, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_x2_75x75 \"Sensitivity: 8.0, Resolution: 75x75, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_x2_75x75 \"Sensitivity: 9.0, Resolution: 75x75, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_x2_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_x2_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_x2_75x75 \"Sensitivity: 10.0, Resolution: 75x75, Luminosity: x2\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_x2_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_x2_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_x2_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Luminosity: x2'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_x2_25x25 \"Sensitivity: 0.0, Resolution: 25x25, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_x2_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_x2_25x25 \"Sensitivity: 2.0, Resolution: 25x25, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_x2_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_x2_25x25 \"Sensitivity: 4.0, Resolution: 25x25, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_x2_25x25 \"Sensitivity: 5.0, Resolution: 25x25, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_x2_25x25 \"Sensitivity: 6.0, Resolution: 25x25, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_x2_25x25 \"Sensitivity: 7.0, Resolution: 25x25, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_x2_25x25 \"Sensitivity: 8.0, Resolution: 25x25, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_x2_25x25 \"Sensitivity: 9.0, Resolution: 25x25, Luminosity: x2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_x2_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_x2_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_x2_25x25 \"Sensitivity: 10.0, Resolution: 25x25, Luminosity: x2\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_x2_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_x2_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_x2_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Luminosity: x2'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smearing scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_0.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_aug_1_std_02_75x75 \"Sensitivity: 0.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_1.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_aug_1_std_02_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_2.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_aug_1_std_02_75x75 \"Sensitivity: 2.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_3.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_aug_1_std_02_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_4.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_aug_1_std_02_75x75 \"Sensitivity: 4.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_5.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_aug_1_std_02_75x75 \"Sensitivity: 5.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_6.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_aug_1_std_02_75x75 \"Sensitivity: 6.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_7.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_aug_1_std_02_75x75 \"Sensitivity: 7.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_8.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_aug_1_std_02_75x75 \"Sensitivity: 8.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_9.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_aug_1_std_02_75x75 \"Sensitivity: 9.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_10.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_aug_1_std_02_75x75 \"Sensitivity: 10.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.2\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/smearing_scale_02/mix_sample_{i:.1f}_aug_1_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_aug_1_std_02_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Augmentation: +1, Smearing: 0.2'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_0.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_aug_1_std_05_75x75 \"Sensitivity: 0.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_1.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_aug_1_std_05_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_2.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_aug_1_std_05_75x75 \"Sensitivity: 2.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_3.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_aug_1_std_05_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_4.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_aug_1_std_05_75x75 \"Sensitivity: 4.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_5.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_aug_1_std_05_75x75 \"Sensitivity: 5.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_6.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_aug_1_std_05_75x75 \"Sensitivity: 6.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_7.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_aug_1_std_05_75x75 \"Sensitivity: 7.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_8.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_aug_1_std_05_75x75 \"Sensitivity: 8.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_9.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_aug_1_std_05_75x75 \"Sensitivity: 9.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_10.0_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_aug_1_std_05_75x75 \"Sensitivity: 10.0, Resolution: 75x75, Augmentation: +1, Smearing: 0.5\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/smearing_scale_05/mix_sample_{i:.1f}_aug_1_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_aug_1_std_05_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Augmentation: +1, Smearing: 0.5'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_0.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_aug_1_std_02_25x25 \"Sensitivity: 0.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_1.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_aug_1_std_02_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_2.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_aug_1_std_02_25x25 \"Sensitivity: 2.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_3.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_aug_1_std_02_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_4.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_aug_1_std_02_25x25 \"Sensitivity: 4.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_5.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_aug_1_std_02_25x25 \"Sensitivity: 5.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_6.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_aug_1_std_02_25x25 \"Sensitivity: 6.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_7.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_aug_1_std_02_25x25 \"Sensitivity: 7.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_8.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_aug_1_std_02_25x25 \"Sensitivity: 8.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_9.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_aug_1_std_02_25x25 \"Sensitivity: 9.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_02/mix_sample_10.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_aug_1_std_02_25x25 \"Sensitivity: 10.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.2\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/smearing_scale_02/mix_sample_{i:.1f}_aug_1_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_aug_1_std_02_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Augmentation: +1, Smearing: 0.2'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_0.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_aug_1_std_05_25x25 \"Sensitivity: 0.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_1.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_aug_1_std_05_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_2.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_aug_1_std_05_25x25 \"Sensitivity: 2.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_3.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_aug_1_std_05_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_4.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_aug_1_std_05_25x25 \"Sensitivity: 4.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_5.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_aug_1_std_05_25x25 \"Sensitivity: 5.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_6.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_aug_1_std_05_25x25 \"Sensitivity: 6.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_7.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_aug_1_std_05_25x25 \"Sensitivity: 7.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_8.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_aug_1_std_05_25x25 \"Sensitivity: 8.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_9.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_aug_1_std_05_25x25 \"Sensitivity: 9.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/smearing_scale_05/mix_sample_10.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_aug_1_std_05_25x25 \"Sensitivity: 10.0, Resolution: 25x25, Augmentation: +1, Smearing: 0.5\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/smearing_scale_05/mix_sample_{i:.1f}_aug_1_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_aug_1_std_05_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Augmentation: +1, Smearing: 0.5'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p_{\\text{T}}$ augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_pt_aug_1_75x75 \"Sensitivity: 0.0, Resolution: 75x75, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_pt_aug_1_75x75 \"Sensitivity: 1.0, Resolution: 75x75, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_pt_aug_1_75x75 \"Sensitivity: 2.0, Resolution: 75x75, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_pt_aug_1_75x75 \"Sensitivity: 3.0, Resolution: 75x75, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_pt_aug_1_75x75 \"Sensitivity: 4.0, Resolution: 75x75, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_pt_aug_1_75x75 \"Sensitivity: 5.0, Resolution: 75x75, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_pt_aug_1_75x75 \"Sensitivity: 6.0, Resolution: 75x75, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_pt_aug_1_75x75 \"Sensitivity: 7.0, Resolution: 75x75, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_pt_aug_1_75x75 \"Sensitivity: 8.0, Resolution: 75x75, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_pt_aug_1_75x75 \"Sensitivity: 9.0, Resolution: 75x75, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_pt_aug_1_75x75 \"Sensitivity: 10.0, Resolution: 75x75, pT smearing: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_1_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_pt_aug_1_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, pT smearing: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_pt_aug_3_75x75 \"Sensitivity: 0.0, Resolution: 75x75, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_pt_aug_3_75x75 \"Sensitivity: 1.0, Resolution: 75x75, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_pt_aug_3_75x75 \"Sensitivity: 2.0, Resolution: 75x75, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_pt_aug_3_75x75 \"Sensitivity: 3.0, Resolution: 75x75, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_pt_aug_3_75x75 \"Sensitivity: 4.0, Resolution: 75x75, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_pt_aug_3_75x75 \"Sensitivity: 5.0, Resolution: 75x75, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_pt_aug_3_75x75 \"Sensitivity: 6.0, Resolution: 75x75, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_pt_aug_3_75x75 \"Sensitivity: 7.0, Resolution: 75x75, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_pt_aug_3_75x75 \"Sensitivity: 8.0, Resolution: 75x75, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_pt_aug_3_75x75 \"Sensitivity: 9.0, Resolution: 75x75, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_pt_aug_3_75x75 \"Sensitivity: 10.0, Resolution: 75x75, pT smearing: +3\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_3_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_pt_aug_3_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, pT smearing: +3'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_pt_aug_5_75x75 \"Sensitivity: 0.0, Resolution: 75x75, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_pt_aug_5_75x75 \"Sensitivity: 1.0, Resolution: 75x75, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_pt_aug_5_75x75 \"Sensitivity: 2.0, Resolution: 75x75, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_pt_aug_5_75x75 \"Sensitivity: 3.0, Resolution: 75x75, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_pt_aug_5_75x75 \"Sensitivity: 4.0, Resolution: 75x75, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_pt_aug_5_75x75 \"Sensitivity: 5.0, Resolution: 75x75, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_pt_aug_5_75x75 \"Sensitivity: 6.0, Resolution: 75x75, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_pt_aug_5_75x75 \"Sensitivity: 7.0, Resolution: 75x75, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_pt_aug_5_75x75 \"Sensitivity: 8.0, Resolution: 75x75, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_pt_aug_5_75x75 \"Sensitivity: 9.0, Resolution: 75x75, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_pt_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_pt_aug_5_75x75 \"Sensitivity: 10.0, Resolution: 75x75, pT smearing: +5\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_5_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_pt_aug_5_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, pT smearing: +5'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_pt_aug_1_25x25 \"Sensitivity: 0.0, Resolution: 25x25, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_pt_aug_1_25x25 \"Sensitivity: 1.0, Resolution: 25x25, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_pt_aug_1_25x25 \"Sensitivity: 2.0, Resolution: 25x25, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_pt_aug_1_25x25 \"Sensitivity: 3.0, Resolution: 25x25, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_pt_aug_1_25x25 \"Sensitivity: 4.0, Resolution: 25x25, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_pt_aug_1_25x25 \"Sensitivity: 5.0, Resolution: 25x25, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_pt_aug_1_25x25 \"Sensitivity: 6.0, Resolution: 25x25, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_pt_aug_1_25x25 \"Sensitivity: 7.0, Resolution: 25x25, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_pt_aug_1_25x25 \"Sensitivity: 8.0, Resolution: 25x25, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_pt_aug_1_25x25 \"Sensitivity: 9.0, Resolution: 25x25, pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_pt_aug_1_25x25 \"Sensitivity: 10.0, Resolution: 25x25, pT smearing: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_pt_aug_1_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_pt_aug_1_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, pT smearing: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_0.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_pt_aug_3_25x25 \"Sensitivity: 0.0, Resolution: 25x25, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_1.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_pt_aug_3_25x25 \"Sensitivity: 1.0, Resolution: 25x25, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_2.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_pt_aug_3_25x25 \"Sensitivity: 2.0, Resolution: 25x25, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_3.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_pt_aug_3_25x25 \"Sensitivity: 3.0, Resolution: 25x25, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_4.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_pt_aug_3_25x25 \"Sensitivity: 4.0, Resolution: 25x25, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_5.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_pt_aug_3_25x25 \"Sensitivity: 5.0, Resolution: 25x25, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_6.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_pt_aug_3_25x25 \"Sensitivity: 6.0, Resolution: 25x25, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_7.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_pt_aug_3_25x25 \"Sensitivity: 7.0, Resolution: 25x25, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_8.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_pt_aug_3_25x25 \"Sensitivity: 8.0, Resolution: 25x25, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_9.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_pt_aug_3_25x25 \"Sensitivity: 9.0, Resolution: 25x25, pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_10.0_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_pt_aug_3_25x25 \"Sensitivity: 10.0, Resolution: 25x25, pT smearing: +3\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_{i:.1f}_pt_aug_3_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_pt_aug_3_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, pT smearing: +3'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_0.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_pt_aug_5_25x25 \"Sensitivity: 0.0, Resolution: 25x25, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_1.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_pt_aug_5_25x25 \"Sensitivity: 1.0, Resolution: 25x25, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_2.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_pt_aug_5_25x25 \"Sensitivity: 2.0, Resolution: 25x25, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_3.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_pt_aug_5_25x25 \"Sensitivity: 3.0, Resolution: 25x25, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_4.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_pt_aug_5_25x25 \"Sensitivity: 4.0, Resolution: 25x25, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_5.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_pt_aug_5_25x25 \"Sensitivity: 5.0, Resolution: 25x25, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_6.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_pt_aug_5_25x25 \"Sensitivity: 6.0, Resolution: 25x25, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_7.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_pt_aug_5_25x25 \"Sensitivity: 7.0, Resolution: 25x25, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_8.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_pt_aug_5_25x25 \"Sensitivity: 8.0, Resolution: 25x25, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_9.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_pt_aug_5_25x25 \"Sensitivity: 9.0, Resolution: 25x25, pT smearing: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_10.0_pt_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_pt_aug_5_25x25 \"Sensitivity: 10.0, Resolution: 25x25, pT smearing: +5\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/pt_smearing/25x25/mix_sample_{i:.1f}_pt_aug_5_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_pt_aug_5_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, pT smearing: +5'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\eta-\\phi$ augmentation + $p_{\\text{T}}$ augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 0.0, Resolution: 75x75, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 1.0, Resolution: 75x75, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 2.0, Resolution: 75x75, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 3.0, Resolution: 75x75, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 4.0, Resolution: 75x75, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 5.0, Resolution: 75x75, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 6.0, Resolution: 75x75, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 7.0, Resolution: 75x75, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 8.0, Resolution: 75x75, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 9.0, Resolution: 75x75, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_eta_phi_pt_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_eta_phi_pt_aug_1_75x75 \"Sensitivity: 10.0, Resolution: 75x75, eta phi pT smearing: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_eta_phi_pt_aug_1_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_eta_phi_pt_aug_1_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, eta phi pT smearing: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_0.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 0.0, Resolution: 75x75, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_1.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 1.0, Resolution: 75x75, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_2.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 2.0, Resolution: 75x75, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_3.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 3.0, Resolution: 75x75, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_4.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 4.0, Resolution: 75x75, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_5.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 5.0, Resolution: 75x75, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_6.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 6.0, Resolution: 75x75, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_7.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 7.0, Resolution: 75x75, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_8.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 8.0, Resolution: 75x75, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_9.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 9.0, Resolution: 75x75, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/split_val/mix_sample_10.0_eta_phi_pt_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_eta_phi_pt_aug_3_75x75 \"Sensitivity: 10.0, Resolution: 75x75, eta phi pT smearing: +3\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_eta_phi_pt_aug_3_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_eta_phi_pt_aug_3_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, eta phi pT smearing: +3'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_0.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 0.0, Resolution: 25x25, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_1.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 1.0, Resolution: 25x25, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_2.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 2.0, Resolution: 25x25, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_3.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 3.0, Resolution: 25x25, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_4.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 4.0, Resolution: 25x25, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_5.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 5.0, Resolution: 25x25, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_6.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 6.0, Resolution: 25x25, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_7.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 7.0, Resolution: 25x25, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_8.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 8.0, Resolution: 25x25, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_9.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 9.0, Resolution: 25x25, eta phi pT smearing: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_10.0_eta_phi_pt_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_eta_phi_pt_aug_1_25x25 \"Sensitivity: 10.0, Resolution: 25x25, eta phi pT smearing: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_{i:.1f}_eta_phi_pt_aug_1_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_eta_phi_pt_aug_1_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, eta phi pT smearing: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_0.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 0.0, Resolution: 25x25, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_1.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 1.0, Resolution: 25x25, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_2.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 2.0, Resolution: 25x25, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_3.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 3.0, Resolution: 25x25, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_4.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 4.0, Resolution: 25x25, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_5.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 5.0, Resolution: 25x25, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_6.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 6.0, Resolution: 25x25, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_7.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 7.0, Resolution: 25x25, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_8.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 8.0, Resolution: 25x25, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_9.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 9.0, Resolution: 25x25, eta phi pT smearing: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_10.0_eta_phi_pt_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_eta_phi_pt_aug_3_25x25 \"Sensitivity: 10.0, Resolution: 25x25, eta phi pT smearing: +3\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/eta_phi_pt_smearing/25x25/mix_sample_{i:.1f}_eta_phi_pt_aug_3_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_eta_phi_pt_aug_3_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, eta phi pT smearing: +3'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jet rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_0.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_jet_aug_1_75x75 \"Sensitivity: 0.0, Resolution: 75x75, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_1.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_jet_aug_1_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_2.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_jet_aug_1_75x75 \"Sensitivity: 2.0, Resolution: 75x75, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_3.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_jet_aug_1_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_4.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_jet_aug_1_75x75 \"Sensitivity: 4.0, Resolution: 75x75, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_5.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_jet_aug_1_75x75 \"Sensitivity: 5.0, Resolution: 75x75, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_6.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_jet_aug_1_75x75 \"Sensitivity: 6.0, Resolution: 75x75, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_7.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_jet_aug_1_75x75 \"Sensitivity: 7.0, Resolution: 75x75, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_8.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_jet_aug_1_75x75 \"Sensitivity: 8.0, Resolution: 75x75, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_9.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_jet_aug_1_75x75 \"Sensitivity: 9.0, Resolution: 75x75, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_10.0_jet_aug_1_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_jet_aug_1_75x75 \"Sensitivity: 10.0, Resolution: 75x75, Jet rotation: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/rotate_jet/mix_sample_{i:.1f}_jet_aug_1_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_jet_aug_1_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Jet rotation: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_0.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_jet_aug_3_75x75 \"Sensitivity: 0.0, Resolution: 75x75, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_1.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_jet_aug_3_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_2.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_jet_aug_3_75x75 \"Sensitivity: 2.0, Resolution: 75x75, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_3.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_jet_aug_3_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_4.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_jet_aug_3_75x75 \"Sensitivity: 4.0, Resolution: 75x75, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_5.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_jet_aug_3_75x75 \"Sensitivity: 5.0, Resolution: 75x75, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_6.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_jet_aug_3_75x75 \"Sensitivity: 6.0, Resolution: 75x75, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_7.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_jet_aug_3_75x75 \"Sensitivity: 7.0, Resolution: 75x75, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_8.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_jet_aug_3_75x75 \"Sensitivity: 8.0, Resolution: 75x75, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_9.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_jet_aug_3_75x75 \"Sensitivity: 9.0, Resolution: 75x75, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_10.0_jet_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_jet_aug_3_75x75 \"Sensitivity: 10.0, Resolution: 75x75, Jet rotation: +3\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/rotate_jet/mix_sample_{i:.1f}_jet_aug_3_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_jet_aug_3_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Jet rotation: +3'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_0.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_jet_aug_5_75x75 \"Sensitivity: 0.0, Resolution: 75x75, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_1.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_jet_aug_5_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_2.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_jet_aug_5_75x75 \"Sensitivity: 2.0, Resolution: 75x75, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_3.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_jet_aug_5_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_4.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_jet_aug_5_75x75 \"Sensitivity: 4.0, Resolution: 75x75, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_5.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_jet_aug_5_75x75 \"Sensitivity: 5.0, Resolution: 75x75, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_6.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_jet_aug_5_75x75 \"Sensitivity: 6.0, Resolution: 75x75, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_7.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_jet_aug_5_75x75 \"Sensitivity: 7.0, Resolution: 75x75, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_8.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_jet_aug_5_75x75 \"Sensitivity: 8.0, Resolution: 75x75, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_9.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_jet_aug_5_75x75 \"Sensitivity: 9.0, Resolution: 75x75, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/rotate_jet/mix_sample_10.0_jet_aug_5_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_jet_aug_5_75x75 \"Sensitivity: 10.0, Resolution: 75x75, Jet rotation: +5\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/rotate_jet/mix_sample_{i:.1f}_jet_aug_5_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_jet_aug_5_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Jet rotation: +5'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_0.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_jet_aug_1_25x25 \"Sensitivity: 0.0, Resolution: 25x25, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_jet_aug_1_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_2.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_jet_aug_1_25x25 \"Sensitivity: 2.0, Resolution: 25x25, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_jet_aug_1_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_4.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_jet_aug_1_25x25 \"Sensitivity: 4.0, Resolution: 25x25, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_5.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_jet_aug_1_25x25 \"Sensitivity: 5.0, Resolution: 25x25, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_6.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_jet_aug_1_25x25 \"Sensitivity: 6.0, Resolution: 25x25, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_7.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_jet_aug_1_25x25 \"Sensitivity: 7.0, Resolution: 25x25, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_8.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_jet_aug_1_25x25 \"Sensitivity: 8.0, Resolution: 25x25, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_9.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_jet_aug_1_25x25 \"Sensitivity: 9.0, Resolution: 25x25, Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_10.0_jet_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_jet_aug_1_25x25 \"Sensitivity: 10.0, Resolution: 25x25, Jet rotation: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_1_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_jet_aug_1_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Jet rotation: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_0.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_jet_aug_3_25x25 \"Sensitivity: 0.0, Resolution: 25x25, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_jet_aug_3_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_2.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_jet_aug_3_25x25 \"Sensitivity: 2.0, Resolution: 25x25, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_jet_aug_3_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_4.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_jet_aug_3_25x25 \"Sensitivity: 4.0, Resolution: 25x25, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_5.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_jet_aug_3_25x25 \"Sensitivity: 5.0, Resolution: 25x25, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_6.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_jet_aug_3_25x25 \"Sensitivity: 6.0, Resolution: 25x25, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_7.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_jet_aug_3_25x25 \"Sensitivity: 7.0, Resolution: 25x25, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_8.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_jet_aug_3_25x25 \"Sensitivity: 8.0, Resolution: 25x25, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_9.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_jet_aug_3_25x25 \"Sensitivity: 9.0, Resolution: 25x25, Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_10.0_jet_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_jet_aug_3_25x25 \"Sensitivity: 10.0, Resolution: 25x25, Jet rotation: +3\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_3_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_jet_aug_3_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Jet rotation: +3'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_0.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_jet_aug_5_25x25 \"Sensitivity: 0.0, Resolution: 25x25, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_jet_aug_5_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_2.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_jet_aug_5_25x25 \"Sensitivity: 2.0, Resolution: 25x25, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_jet_aug_5_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_4.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_jet_aug_5_25x25 \"Sensitivity: 4.0, Resolution: 25x25, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_5.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_jet_aug_5_25x25 \"Sensitivity: 5.0, Resolution: 25x25, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_6.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_jet_aug_5_25x25 \"Sensitivity: 6.0, Resolution: 25x25, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_7.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_jet_aug_5_25x25 \"Sensitivity: 7.0, Resolution: 25x25, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_8.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_jet_aug_5_25x25 \"Sensitivity: 8.0, Resolution: 25x25, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_9.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_jet_aug_5_25x25 \"Sensitivity: 9.0, Resolution: 25x25, Jet rotation: +5\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_10.0_jet_aug_5_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_jet_aug_5_25x25 \"Sensitivity: 10.0, Resolution: 25x25, Jet rotation: +5\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_5_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_jet_aug_5_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Jet rotation: +5'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_7_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_jet_aug_7_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Jet rotation: +7\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_10_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_jet_aug_10_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Jet rotation: +10\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_15_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_jet_aug_15_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Jet rotation: +15\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_22_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_jet_aug_22_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Jet rotation: +22\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_33_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_jet_aug_33_75x75 \"Sensitivity: 3.0, Resolution: 75x75, Jet rotation: +33\"\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "for n in [7, 10, 15, 22, 33]:\n",
    "    train_file = f'../Sample/HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_{n}_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_jet_aug_{n}_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Jet rotation: +{n}'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_7_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_jet_aug_7_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Jet rotation: +7\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_10_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_jet_aug_10_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Jet rotation: +10\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_15_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_jet_aug_15_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Jet rotation: +15\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_3.0_jet_aug_22_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_jet_aug_22_25x25 \"Sensitivity: 3.0, Resolution: 25x25, Jet rotation: +22\"\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "for n in [7, 10, 15, 22]:\n",
    "    train_file = f'../Sample/HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_{n}_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_jet_aug_{n}_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Jet rotation: +{n}'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_7_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_jet_aug_7_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Jet rotation: +7\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_10_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_jet_aug_10_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Jet rotation: +10\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_15_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_jet_aug_15_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Jet rotation: +15\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_22_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_jet_aug_22_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Jet rotation: +22\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_33_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_jet_aug_33_75x75 \"Sensitivity: 1.0, Resolution: 75x75, Jet rotation: +33\"\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for n in [7, 10, 15, 22, 33]:\n",
    "    train_file = f'../Sample/HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_{n}_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_jet_aug_{n}_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, Jet rotation: +{n}'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_7_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_jet_aug_7_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Jet rotation: +7\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_10_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_jet_aug_10_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Jet rotation: +10\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_15_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_jet_aug_15_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Jet rotation: +15\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/jet_rotation/mix_sample_1.0_jet_aug_22_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_jet_aug_22_25x25 \"Sensitivity: 1.0, Resolution: 25x25, Jet rotation: +22\"\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for n in [7, 10, 15, 22]:\n",
    "    train_file = f'../Sample/HVmodel/data/jet_rotation/mix_sample_{i:.1f}_jet_aug_{n}_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_jet_aug_{n}_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, Jet rotation: +{n}'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p_\\text{T}$ smearing + jet rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_0.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_pT_jet_aug_1_25x25 \"Sensitivity: 0.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_1.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_pT_jet_aug_1_25x25 \"Sensitivity: 1.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_2.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_pT_jet_aug_1_25x25 \"Sensitivity: 2.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_3.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_pT_jet_aug_1_25x25 \"Sensitivity: 3.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_4.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_pT_jet_aug_1_25x25 \"Sensitivity: 4.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_5.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_pT_jet_aug_1_25x25 \"Sensitivity: 5.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_6.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_pT_jet_aug_1_25x25 \"Sensitivity: 6.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_7.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_pT_jet_aug_1_25x25 \"Sensitivity: 7.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_8.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_pT_jet_aug_1_25x25 \"Sensitivity: 8.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_9.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_pT_jet_aug_1_25x25 \"Sensitivity: 9.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_10.0_aug_1_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_pT_jet_aug_1_25x25 \"Sensitivity: 10.0, Resolution: 25x25, pT smearing + Jet rotation: +1\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_{i:.1f}_aug_1_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_pT_jet_aug_1_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, pT smearing + Jet rotation: +1'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_0.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_0.0_pT_jet_aug_3_25x25 \"Sensitivity: 0.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_1.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_1.0_pT_jet_aug_3_25x25 \"Sensitivity: 1.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_2.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_2.0_pT_jet_aug_3_25x25 \"Sensitivity: 2.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_3.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_3.0_pT_jet_aug_3_25x25 \"Sensitivity: 3.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_4.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_4.0_pT_jet_aug_3_25x25 \"Sensitivity: 4.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_5.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_5.0_pT_jet_aug_3_25x25 \"Sensitivity: 5.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_6.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_6.0_pT_jet_aug_3_25x25 \"Sensitivity: 6.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_7.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_7.0_pT_jet_aug_3_25x25 \"Sensitivity: 7.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_8.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_8.0_pT_jet_aug_3_25x25 \"Sensitivity: 8.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_9.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_9.0_pT_jet_aug_3_25x25 \"Sensitivity: 9.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_10.0_aug_3_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_25x25.npy ../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy SB_10.0_pT_jet_aug_3_25x25 \"Sensitivity: 10.0, Resolution: 25x25, pT smearing + Jet rotation: +3\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/mix_sample_{i:.1f}_aug_3_25x25.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_25x25.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_25x25.npy'\n",
    "    model_name = f'SB_{i:.1f}_pT_jet_aug_3_25x25'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 25x25, pT smearing + Jet rotation: +3'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_0.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_0.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_0.0_pT_jet_aug_3_75x75 \"Sensitivity: 0.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_1.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_1.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_1.0_pT_jet_aug_3_75x75 \"Sensitivity: 1.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_2.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_2.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_2.0_pT_jet_aug_3_75x75 \"Sensitivity: 2.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_3.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_3.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_3.0_pT_jet_aug_3_75x75 \"Sensitivity: 3.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_4.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_4.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_4.0_pT_jet_aug_3_75x75 \"Sensitivity: 4.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_5.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_5.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_5.0_pT_jet_aug_3_75x75 \"Sensitivity: 5.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_6.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_6.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_6.0_pT_jet_aug_3_75x75 \"Sensitivity: 6.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_7.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_7.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_7.0_pT_jet_aug_3_75x75 \"Sensitivity: 7.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_8.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_8.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_8.0_pT_jet_aug_3_75x75 \"Sensitivity: 8.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_9.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_9.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_9.0_pT_jet_aug_3_75x75 \"Sensitivity: 9.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n",
      "python train_CNN.py ../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_10.0_aug_3_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_10.0_val_75x75.npy ../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy SB_10.0_pT_jet_aug_3_75x75 \"Sensitivity: 10.0, Resolution: 75x75, pT smearing + Jet rotation: +3\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    train_file = f'../Sample/HVmodel/data/pt_smearing_jet_rotation/75x75/mix_sample_{i:.1f}_aug_3_75x75.npy'\n",
    "    val_file = f'../Sample/HVmodel/data/split_val/mix_sample_{i:.1f}_val_75x75.npy'\n",
    "    true_label_file = '../Sample/HVmodel/data/split_val/mix_sample_test_75x75.npy'\n",
    "    model_name = f'SB_{i:.1f}_pT_jet_aug_3_75x75'\n",
    "    sample_type = f'Sensitivity: {i:.1f}, Resolution: 75x75, pT smearing + Jet rotation: +3'\n",
    "    cmd = f'python train_CNN.py {train_file} {val_file} {true_label_file} {model_name} \"{sample_type}\"'\n",
    "    print(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
