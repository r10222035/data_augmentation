{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 15:30:36.649287: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 15:30:36.722811: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils_CNN as utils\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# solve the problem of \"libdevice not found at ./libdevice.10.bc\"\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/home/r10222035/.conda/envs/tf2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sculpting_sensitivity(SR_eff, SB_eff, B):\n",
    "    # SR_eff: background efficiency in signal region\n",
    "    # SB_eff: background efficiency in sideband region\n",
    "    # B: number of background events in signal region\n",
    "    \n",
    "    nS = B * (SR_eff - SB_eff)\n",
    "    nB = B * SB_eff\n",
    "    return nS / nB**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SRfpr_from_SBfpr(X_SRSB, y_SRSB, model_name, bkg_effs=[0.1]):\n",
    "    # get the fpr in signal region from the fpr in sideband region\n",
    "    # fpr: false positive rate, background efficiency\n",
    "\n",
    "    save_model_name = f'./CNN_models/last_model_CWoLa_hunting_{model_name}/'\n",
    "    loaded_model = tf.keras.models.load_model(save_model_name)\n",
    "\n",
    "    X_SR, X_SB = X_SRSB\n",
    "    y_SR, y_SB = y_SRSB\n",
    "\n",
    "    y_prob_SB = loaded_model.predict(X_SB)\n",
    "    fpr_SB, th_SB = utils.get_fpr_thresholds(y_SB == 1, y_prob_SB)\n",
    "\n",
    "    y_prob_SR = loaded_model.predict(X_SR)\n",
    "    fpr_SR, th_SR = utils.get_fpr_thresholds(y_SR == 1, y_prob_SR)\n",
    "\n",
    "\n",
    "    bkg_effs_SR = []\n",
    "    for bkg_eff in bkg_effs:\n",
    "        th_SB_bkg_eff = utils.get_threshold_from_fpr(fpr_SB, th_SB, bkg_eff)\n",
    "        n_th = (th_SR < th_SB_bkg_eff).sum()\n",
    "        bkg_effs_SR.append(fpr_SR[n_th])\n",
    "\n",
    "    return bkg_effs_SR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background cross section, SR: 136.13 fb, SB: 145.57 fb\n",
      "Background sample size: SR: 18922.4, SB: 20234.0\n",
      "Signal sample size: SR: 0.0, SB: 0.0\n",
      "Preparing dataset from ['../Sample/HVmodel/data/origin/25x25']\n"
     ]
    }
   ],
   "source": [
    "config_file = 'config_files/origin_config_01.json'\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "train_npy_paths = config['train_npy_paths']\n",
    "seed = config['seed']\n",
    "sensitivity = config['sensitivity']\n",
    "\n",
    "model_name = 'SB_0.0_25x25'\n",
    "\n",
    "# Training and validation splitting ratio\n",
    "r_train, r_val = 0.8, 0.2\n",
    "\n",
    "n_SR_S, n_SR_B, n_SB_S, n_SB_B = utils.compute_nevent_in_SR_SB(sensitivity=sensitivity)\n",
    "\n",
    "train_nevents = int(n_SR_S * r_train), int(n_SB_S * r_train), int(n_SR_B * r_train), int(n_SB_B * r_train)\n",
    "X_train_SR, y_train_SR, X_train_SB, y_train_SB  = utils.get_SR_SB_sample_from_npy(train_npy_paths, train_nevents, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 15:30:45.406330: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 15:30:46.017232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46699 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "2024-06-04 15:30:48.829640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34/506 [=>............................] - ETA: 2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 15:30:50.444810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 6s 5ms/step\n",
      "474/474 [==============================] - 2s 5ms/step\n",
      " 0.100  0.1238  10.4\n",
      " 0.010  0.0202  14.1\n",
      " 0.001  0.0022  5.4\n"
     ]
    }
   ],
   "source": [
    "SB_effs = [0.1, 0.01, 0.001]\n",
    "SR_effs = get_SRfpr_from_SBfpr((X_train_SR, X_train_SB), (y_train_SR, y_train_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    print(f'{SB_eff: .3f} {SR_eff: .4f} {sculpting_sensitivity(SR_eff, SB_eff, n_SR_B): .1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_SR, y_test_SR = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test.npy')\n",
    "X_test_SB, y_test_SB = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test-SB.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 5ms/step\n",
      "625/625 [==============================] - 3s 5ms/step\n",
      " 0.100  0.1071  3.1\n",
      " 0.010  0.0172  9.9\n",
      " 0.001  0.0006 -1.7\n"
     ]
    }
   ],
   "source": [
    "SR_effs = get_SRfpr_from_SBfpr((X_test_SR, X_test_SB), (y_test_SR, y_test_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    print(f'{SB_eff: .3f} {SR_eff: .4f} {sculpting_sensitivity(SR_eff, SB_eff, n_SR_B): .1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +3 Jet rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background cross section, SR: 136.13 fb, SB: 145.57 fb\n",
      "Background sample size: SR: 18922.4, SB: 20234.0\n",
      "Signal sample size: SR: 0.0, SB: 0.0\n",
      "Preparing dataset from ['../Sample/HVmodel/data/origin/25x25', '../Sample/HVmodel/data/jet_rotation/25x25/01', '../Sample/HVmodel/data/jet_rotation/25x25/02', '../Sample/HVmodel/data/jet_rotation/25x25/03']\n"
     ]
    }
   ],
   "source": [
    "config_file = 'config_files/jet_aug_3_config_01.json'\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "train_npy_paths = config['train_npy_paths']\n",
    "seed = config['seed']\n",
    "sensitivity = config['sensitivity']\n",
    "\n",
    "model_name = config['model_name']\n",
    "\n",
    "# Training and validation splitting ratio\n",
    "r_train, r_val = 0.8, 0.2\n",
    "\n",
    "n_SR_S, n_SR_B, n_SB_S, n_SB_B = utils.compute_nevent_in_SR_SB(sensitivity=sensitivity)\n",
    "\n",
    "train_nevents = int(n_SR_S * r_train), int(n_SB_S * r_train), int(n_SR_B * r_train), int(n_SB_B * r_train)\n",
    "X_train_SR, y_train_SR, X_train_SB, y_train_SB  = utils.get_SR_SB_sample_from_npy(train_npy_paths, train_nevents, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/2024 [==============================] - 10s 5ms/step\n",
      "1893/1893 [==============================] - 10s 5ms/step\n",
      " 0.100  0.1421  18.3\n",
      " 0.010  0.0268  23.1\n",
      " 0.001  0.0011  0.5\n"
     ]
    }
   ],
   "source": [
    "SB_effs = [0.1, 0.01, 0.001]\n",
    "SR_effs = get_SRfpr_from_SBfpr((X_train_SR, X_train_SB), (y_train_SR, y_train_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    print(f'{SB_eff: .3f} {SR_eff: .4f} {sculpting_sensitivity(SR_eff, SB_eff, n_SR_B): .1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_SR, y_test_SR = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test.npy')\n",
    "X_test_SB, y_test_SB = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test-SB.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 5ms/step\n",
      "625/625 [==============================] - 3s 5ms/step\n",
      " 0.100  0.1118  5.1\n",
      " 0.010  0.0216  16.0\n",
      " 0.001  0.0003 -3.0\n"
     ]
    }
   ],
   "source": [
    "SR_effs = get_SRfpr_from_SBfpr((X_test_SR, X_test_SB), (y_test_SR, y_test_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    print(f'{SB_eff: .3f} {SR_eff: .4f} {sculpting_sensitivity(SR_eff, SB_eff, n_SR_B): .1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +3 $p_\\text{T}$ smearing + Jet rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background cross section, SR: 136.13 fb, SB: 145.57 fb\n",
      "Background sample size: SR: 18922.4, SB: 20234.0\n",
      "Signal sample size: SR: 0.0, SB: 0.0\n",
      "Preparing dataset from ['../Sample/HVmodel/data/origin/25x25', '../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/01', '../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/02', '../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/03']\n"
     ]
    }
   ],
   "source": [
    "config_file = 'config_files/pt_jet_aug_3_config_01.json'\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "train_npy_paths = config['train_npy_paths']\n",
    "seed = config['seed']\n",
    "sensitivity = config['sensitivity']\n",
    "\n",
    "model_name = config['model_name']\n",
    "\n",
    "# Training and validation splitting ratio\n",
    "r_train, r_val = 0.8, 0.2\n",
    "\n",
    "n_SR_S, n_SR_B, n_SB_S, n_SB_B = utils.compute_nevent_in_SR_SB(sensitivity=sensitivity)\n",
    "\n",
    "train_nevents = int(n_SR_S * r_train), int(n_SB_S * r_train), int(n_SR_B * r_train), int(n_SB_B * r_train)\n",
    "X_train_SR, y_train_SR, X_train_SB, y_train_SB  = utils.get_SR_SB_sample_from_npy(train_npy_paths, train_nevents, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/2024 [==============================] - 10s 5ms/step\n",
      "1893/1893 [==============================] - 10s 5ms/step\n",
      " 0.100  0.1318  13.9\n",
      " 0.010  0.0212  15.4\n",
      " 0.001  0.0020  4.4\n"
     ]
    }
   ],
   "source": [
    "SB_effs = [0.1, 0.01, 0.001]\n",
    "SR_effs = get_SRfpr_from_SBfpr((X_train_SR, X_train_SB), (y_train_SR, y_train_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    print(f'{SB_eff: .3f} {SR_eff: .4f} {sculpting_sensitivity(SR_eff, SB_eff, n_SR_B): .1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_SR, y_test_SR = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test.npy')\n",
    "X_test_SB, y_test_SB = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test-SB.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 5ms/step\n",
      "625/625 [==============================] - 3s 5ms/step\n",
      " 0.100  0.1148  6.4\n",
      " 0.010  0.0163  8.7\n",
      " 0.001  0.0011  0.4\n"
     ]
    }
   ],
   "source": [
    "SR_effs = get_SRfpr_from_SBfpr((X_test_SR, X_test_SB), (y_test_SR, y_test_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    print(f'{SB_eff: .3f} {SR_eff: .4f} {sculpting_sensitivity(SR_eff, SB_eff, n_SR_B): .1f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
