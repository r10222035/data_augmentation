{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:30:17.139622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 15:30:17.214513: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils_CNN as utils\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# solve the problem of \"libdevice not found at ./libdevice.10.bc\"\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/home/r10222035/.conda/envs/tf2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sculpting_sensitivity_and_uncertainty(SR_eff, SB_eff, B, N_SR):\n",
    "    # SR_eff: background efficiency in signal region\n",
    "    # SB_eff: background efficiency in sideband region\n",
    "    # B: number of background events in signal region\n",
    "    # N_SR: number of events used to calculate SR_eff\n",
    "    \n",
    "    nS = B * (SR_eff - SB_eff)\n",
    "    nB = B * SB_eff\n",
    "    sigma = nS / nB**0.5\n",
    "    unceitatinty = (B / SB_eff)**0.5 * (SR_eff * (1 - SR_eff) / N_SR)**0.5\n",
    "    return sigma, unceitatinty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SRfpr_from_SBfpr(X_SRSB, y_SRSB, model_name, bkg_effs=[0.1]):\n",
    "    # get the fpr in signal region from the fpr in sideband region\n",
    "    # fpr: false positive rate, background efficiency\n",
    "\n",
    "    save_model_name = f'./CNN_models/last_model_CWoLa_hunting_{model_name}/'\n",
    "    loaded_model = tf.keras.models.load_model(save_model_name)\n",
    "\n",
    "    X_SR, X_SB = X_SRSB\n",
    "    y_SR, y_SB = y_SRSB\n",
    "\n",
    "    y_prob_SB = loaded_model.predict(X_SB, batch_size=1024)\n",
    "    fpr_SB, th_SB = utils.get_fpr_thresholds(y_SB == 1, y_prob_SB)\n",
    "\n",
    "    y_prob_SR = loaded_model.predict(X_SR, batch_size=1024)\n",
    "    fpr_SR, th_SR = utils.get_fpr_thresholds(y_SR == 1, y_prob_SR)\n",
    "\n",
    "\n",
    "    bkg_effs_SR = []\n",
    "    for bkg_eff in bkg_effs:\n",
    "        th_SB_bkg_eff = utils.get_threshold_from_fpr(fpr_SB, th_SB, bkg_eff)\n",
    "        n_th = (th_SR < th_SB_bkg_eff).sum()\n",
    "        bkg_effs_SR.append(fpr_SR[n_th])\n",
    "\n",
    "    return bkg_effs_SR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background cross section, SR: 136.13 fb, SB: 145.57 fb\n",
      "Background sample size: SR: 18922.4, SB: 20234.0\n",
      "Signal sample size: SR: 0.0, SB: 0.0\n",
      "Preparing dataset from ['../Sample/HVmodel/data/origin/25x25']\n"
     ]
    }
   ],
   "source": [
    "config_file = 'config_files/origin_config_01.json'\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "train_npy_paths = config['train_npy_paths']\n",
    "seed = config['seed']\n",
    "sensitivity = config['sensitivity']\n",
    "\n",
    "model_name = 'SB_0.0_25x25'\n",
    "\n",
    "# Training and validation splitting ratio\n",
    "r_train, r_val = 0.8, 0.2\n",
    "\n",
    "n_SR_S, n_SR_B, n_SB_S, n_SB_B = utils.compute_nevent_in_SR_SB(sensitivity=sensitivity)\n",
    "\n",
    "train_nevents = int(n_SR_S * r_train), int(n_SB_S * r_train), int(n_SR_B * r_train), int(n_SB_B * r_train)\n",
    "X_train_SR, y_train_SR, X_train_SB, y_train_SB  = utils.get_SR_SB_sample_from_npy(train_npy_paths, train_nevents, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:30:24.631142: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 15:30:25.233887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46699 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "2024-06-05 15:30:28.053229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/16 [===============>..............] - ETA: 0s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:30:29.710795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 15ms/step\n",
      "15/15 [==============================] - 0s 16ms/step\n",
      "10.00 \\% & 12.37 \\% & $10.3 \\pm 1.2$\n",
      "1.00 \\% & 2.02 \\% & $14.1 \\pm 1.6$\n",
      "0.10 \\% & 0.22 \\% & $5.4 \\pm 1.7$\n"
     ]
    }
   ],
   "source": [
    "SB_effs = [0.1, 0.01, 0.001]\n",
    "SR_effs = get_SRfpr_from_SBfpr((X_train_SR, X_train_SB), (y_train_SR, y_train_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    sigma, uncertainty = sculpting_sensitivity_and_uncertainty(SR_eff, SB_eff, n_SR_B, (y_train_SR == 0).sum())\n",
    "    print(f'{SB_eff * 100:.2f} \\% & {SR_eff * 100:.2f} \\% & ${sigma:.1f} \\pm {uncertainty:.1f}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_SR, y_test_SR = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test.npy')\n",
    "X_test_SB, y_test_SB = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test-SB.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 12ms/step\n",
      "20/20 [==============================] - 0s 7ms/step\n",
      "10.00 \\% & 10.71 \\% & $3.1 \\pm 1.3$\n",
      "1.00 \\% & 1.71 \\% & $9.8 \\pm 1.8$\n",
      "0.10 \\% & 0.06 \\% & $-1.7 \\pm 1.1$\n"
     ]
    }
   ],
   "source": [
    "SR_effs = get_SRfpr_from_SBfpr((X_test_SR, X_test_SB), (y_test_SR, y_test_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    sigma, uncertainty = sculpting_sensitivity_and_uncertainty(SR_eff, SB_eff, n_SR_B, (y_test_SR == 0).sum())\n",
    "    print(f'{SB_eff * 100:.2f} \\% & {SR_eff * 100:.2f} \\% & ${sigma:.1f} \\pm {uncertainty:.1f}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +3 Jet rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background cross section, SR: 136.13 fb, SB: 145.57 fb\n",
      "Background sample size: SR: 18922.4, SB: 20234.0\n",
      "Signal sample size: SR: 0.0, SB: 0.0\n",
      "Preparing dataset from ['../Sample/HVmodel/data/origin/25x25', '../Sample/HVmodel/data/jet_rotation/25x25/01', '../Sample/HVmodel/data/jet_rotation/25x25/02', '../Sample/HVmodel/data/jet_rotation/25x25/03']\n"
     ]
    }
   ],
   "source": [
    "config_file = 'config_files/jet_aug_3_config_01.json'\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "train_npy_paths = config['train_npy_paths']\n",
    "seed = config['seed']\n",
    "sensitivity = config['sensitivity']\n",
    "\n",
    "model_name = config['model_name']\n",
    "\n",
    "# Training and validation splitting ratio\n",
    "r_train, r_val = 0.8, 0.2\n",
    "\n",
    "n_SR_S, n_SR_B, n_SB_S, n_SB_B = utils.compute_nevent_in_SR_SB(sensitivity=sensitivity)\n",
    "\n",
    "train_nevents = int(n_SR_S * r_train), int(n_SB_S * r_train), int(n_SR_B * r_train), int(n_SB_B * r_train)\n",
    "X_train_SR, y_train_SR, X_train_SB, y_train_SB  = utils.get_SR_SB_sample_from_npy(train_npy_paths, train_nevents, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 8ms/step\n",
      "60/60 [==============================] - 1s 8ms/step\n",
      "10.00 \\% & 14.21 \\% & $18.3 \\pm 0.6$\n",
      "1.00 \\% & 2.68 \\% & $23.1 \\pm 0.9$\n",
      "0.10 \\% & 0.11 \\% & $0.5 \\pm 0.6$\n"
     ]
    }
   ],
   "source": [
    "SB_effs = [0.1, 0.01, 0.001]\n",
    "SR_effs = get_SRfpr_from_SBfpr((X_train_SR, X_train_SB), (y_train_SR, y_train_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    sigma, uncertainty = sculpting_sensitivity_and_uncertainty(SR_eff, SB_eff, n_SR_B, (y_train_SR == 0).sum())\n",
    "    print(f'{SB_eff * 100:.2f} \\% & {SR_eff * 100:.2f} \\% & ${sigma:.1f} \\pm {uncertainty:.1f}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_SR, y_test_SR = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test.npy')\n",
    "X_test_SB, y_test_SB = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test-SB.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step\n",
      "20/20 [==============================] - 0s 7ms/step\n",
      "10.00 \\% & 11.18 \\% & $5.1 \\pm 1.4$\n",
      "1.00 \\% & 2.16 \\% & $16.0 \\pm 2.0$\n",
      "0.10 \\% & 0.03 \\% & $-3.0 \\pm 0.8$\n"
     ]
    }
   ],
   "source": [
    "SR_effs = get_SRfpr_from_SBfpr((X_test_SR, X_test_SB), (y_test_SR, y_test_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    sigma, uncertainty = sculpting_sensitivity_and_uncertainty(SR_eff, SB_eff, n_SR_B, (y_test_SR == 0).sum())\n",
    "    print(f'{SB_eff * 100:.2f} \\% & {SR_eff * 100:.2f} \\% & ${sigma:.1f} \\pm {uncertainty:.1f}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +3 $p_\\text{T}$ smearing + Jet rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background cross section, SR: 136.13 fb, SB: 145.57 fb\n",
      "Background sample size: SR: 18922.4, SB: 20234.0\n",
      "Signal sample size: SR: 0.0, SB: 0.0\n",
      "Preparing dataset from ['../Sample/HVmodel/data/origin/25x25', '../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/01', '../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/02', '../Sample/HVmodel/data/pt_smearing_jet_rotation/25x25/03']\n"
     ]
    }
   ],
   "source": [
    "config_file = 'config_files/pt_jet_aug_3_config_01.json'\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "train_npy_paths = config['train_npy_paths']\n",
    "seed = config['seed']\n",
    "sensitivity = config['sensitivity']\n",
    "\n",
    "model_name = config['model_name']\n",
    "\n",
    "# Training and validation splitting ratio\n",
    "r_train, r_val = 0.8, 0.2\n",
    "\n",
    "n_SR_S, n_SR_B, n_SB_S, n_SB_B = utils.compute_nevent_in_SR_SB(sensitivity=sensitivity)\n",
    "\n",
    "train_nevents = int(n_SR_S * r_train), int(n_SB_S * r_train), int(n_SR_B * r_train), int(n_SB_B * r_train)\n",
    "X_train_SR, y_train_SR, X_train_SB, y_train_SB  = utils.get_SR_SB_sample_from_npy(train_npy_paths, train_nevents, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 7ms/step\n",
      "60/60 [==============================] - 0s 7ms/step\n",
      "10.00 \\% & 13.18 \\% & $13.9 \\pm 0.6$\n",
      "1.00 \\% & 2.11 \\% & $15.3 \\pm 0.8$\n",
      "0.10 \\% & 0.20 \\% & $4.4 \\pm 0.8$\n"
     ]
    }
   ],
   "source": [
    "SB_effs = [0.1, 0.01, 0.001]\n",
    "SR_effs = get_SRfpr_from_SBfpr((X_train_SR, X_train_SB), (y_train_SR, y_train_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    sigma, uncertainty = sculpting_sensitivity_and_uncertainty(SR_eff, SB_eff, n_SR_B, (y_train_SR == 0).sum())\n",
    "    print(f'{SB_eff * 100:.2f} \\% & {SR_eff * 100:.2f} \\% & ${sigma:.1f} \\pm {uncertainty:.1f}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_SR, y_test_SR = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test.npy')\n",
    "X_test_SB, y_test_SB = utils.load_samples('../Sample/HVmodel/data/split_val/25x25/mix_sample_test-SB.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step\n",
      "20/20 [==============================] - 0s 7ms/step\n",
      "10.00 \\% & 11.50 \\% & $6.5 \\pm 1.4$\n",
      "1.00 \\% & 1.63 \\% & $8.7 \\pm 1.7$\n",
      "0.10 \\% & 0.11 \\% & $0.4 \\pm 1.4$\n"
     ]
    }
   ],
   "source": [
    "SR_effs = get_SRfpr_from_SBfpr((X_test_SR, X_test_SB), (y_test_SR, y_test_SB), model_name, SB_effs)\n",
    "\n",
    "for SB_eff, SR_eff in zip(SB_effs, SR_effs):\n",
    "    sigma, uncertainty = sculpting_sensitivity_and_uncertainty(SR_eff, SB_eff, n_SR_B, (y_test_SR == 0).sum())\n",
    "    print(f'{SB_eff * 100:.2f} \\% & {SR_eff * 100:.2f} \\% & ${sigma:.1f} \\pm {uncertainty:.1f}$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
