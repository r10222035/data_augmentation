{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa35fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 17:12:06.467011: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-29 17:12:06.549399: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils_CNN as utils\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "# solve the problem of \"libdevice not found at ./libdevice.10.bc\"\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/home/r10222035/.conda/envs/tf2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b0772",
   "metadata": {},
   "source": [
    "# Sampling datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d198aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_size(y):\n",
    "    if len(y.shape) == 1:\n",
    "        ns = (y == 1).sum()\n",
    "        nb = (y == 0).sum()\n",
    "    else:\n",
    "        ns = (y.argmax(axis=1) == 1).sum()\n",
    "        nb = (y.argmax(axis=1) == 0).sum()\n",
    "    print(ns, nb)\n",
    "    return ns, nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159a790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config_files/origin_25x25_config_01.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8047d335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background cross section, SR: 136.13 fb, SB: 145.57 fb\n",
      "Background sample size: SR: 18922.4, SB: 20234.0\n",
      "Signal sample size: SR: 0.0, SB: 0.0\n",
      "Preparing dataset from ['../Sample/HVmodel/data/origin/25x25']\n"
     ]
    }
   ],
   "source": [
    "# Read config file\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "train_npy_paths = config['train_npy_paths']\n",
    "val_npy_paths = config['val_npy_paths']\n",
    "seed = config['seed']\n",
    "sensitivity = config['sensitivity']\n",
    "luminosity = config['luminosity']\n",
    "\n",
    "true_label_path = config['true_label_path']\n",
    "model_name = config['model_name']\n",
    "sample_type = config['sample_type']\n",
    "\n",
    "# Sampling dataset\n",
    "# r_train, r_val = 1.0, 0.2\n",
    "n_SR_S, n_SR_B, n_SB_S, n_SB_B = utils.compute_nevent_in_SR_SB(sensitivity=sensitivity, L=luminosity)\n",
    "\n",
    "nevents = np.array([n_SR_S, n_SB_S, n_SR_B, n_SB_B]).astype(int)\n",
    "X, y = utils.create_mix_sample_from_npy(train_npy_paths, nevents, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f620b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義k-fold的數量\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "065a7d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18922 20233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18922, 20233)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample_size(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75846115",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f64d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self, name='CNN'):\n",
    "        super(CNN, self).__init__(name=name)\n",
    "\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.sub_network = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "        ])\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        # split two channels\n",
    "        channel1, channel2 = tf.split(inputs, num_or_size_splits=2, axis=-1)\n",
    "\n",
    "        # pass through the same CNN\n",
    "        channel1 = self.bn1(channel1)\n",
    "        channel2 = self.bn2(channel2)\n",
    "        output_channel1 = self.sub_network(channel1)\n",
    "        output_channel2 = self.sub_network(channel2)\n",
    "\n",
    "        # multiply the output\n",
    "        output = tf.multiply(output_channel1, output_channel2)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed89563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "train_epochs = 500\n",
    "patience = 3\n",
    "min_delta = 0.\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f2ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 17:12:20.685815: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-06-29 17:12:20.685875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pheno-2\n",
      "2024-06-29 17:12:20.685883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pheno-2\n",
      "2024-06-29 17:12:20.686766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.256.2\n",
      "2024-06-29 17:12:20.686797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.239.6\n",
      "2024-06-29 17:12:20.686803: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 470.239.6 does not match DSO version 470.256.2 -- cannot find working devices in this configuration\n",
      "2024-06-29 17:12:20.687381: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6505 - accuracy: 0.6455\n",
      "Epoch 1: val_loss improved from inf to 0.99820, saving model to CNN_models/last_model_CNN_1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 12s 159ms/step - loss: 0.6505 - accuracy: 0.6455 - val_loss: 0.9982 - val_accuracy: 0.0139\n",
      "Epoch 2/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6496 - accuracy: 0.6460\n",
      "Epoch 2: val_loss improved from 0.99820 to 0.96957, saving model to CNN_models/last_model_CNN_1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 148ms/step - loss: 0.6495 - accuracy: 0.6461 - val_loss: 0.9696 - val_accuracy: 0.0272\n",
      "Epoch 3/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6494 - accuracy: 0.6456\n",
      "Epoch 3: val_loss did not improve from 0.96957\n",
      "62/62 [==============================] - 8s 123ms/step - loss: 0.6492 - accuracy: 0.6458 - val_loss: 0.9865 - val_accuracy: 0.0106\n",
      "Epoch 4/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6492 - accuracy: 0.6459\n",
      "Epoch 4: val_loss did not improve from 0.96957\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 0.6491 - accuracy: 0.6460 - val_loss: 1.0604 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6493 - accuracy: 0.6463\n",
      "Epoch 5: val_loss did not improve from 0.96957\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 0.6493 - accuracy: 0.6463 - val_loss: 0.9715 - val_accuracy: 0.0138\n",
      "Epoch 5: early stopping\n",
      "Epoch 1/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6523 - accuracy: 0.6458\n",
      "Epoch 1: val_loss improved from inf to 0.97338, saving model to CNN_models/last_model_CNN_2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 11s 155ms/step - loss: 0.6522 - accuracy: 0.6459 - val_loss: 0.9734 - val_accuracy: 0.0310\n",
      "Epoch 2/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6501 - accuracy: 0.6460\n",
      "Epoch 2: val_loss did not improve from 0.97338\n",
      "62/62 [==============================] - 8s 126ms/step - loss: 0.6502 - accuracy: 0.6458 - val_loss: 1.0272 - val_accuracy: 2.5540e-04\n",
      "Epoch 3/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6504 - accuracy: 0.6455\n",
      "Epoch 3: val_loss did not improve from 0.97338\n",
      "62/62 [==============================] - 8s 124ms/step - loss: 0.6503 - accuracy: 0.6456 - val_loss: 1.0174 - val_accuracy: 2.5540e-04\n",
      "Epoch 4/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6499 - accuracy: 0.6458\n",
      "Epoch 4: val_loss did not improve from 0.97338\n",
      "62/62 [==============================] - 8s 125ms/step - loss: 0.6499 - accuracy: 0.6459 - val_loss: 1.0205 - val_accuracy: 2.5540e-04\n",
      "Epoch 4: early stopping\n",
      "Epoch 1/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.7061 - accuracy: 0.5155\n",
      "Epoch 1: val_loss improved from inf to 0.76668, saving model to CNN_models/last_model_CNN_3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 11s 155ms/step - loss: 0.7061 - accuracy: 0.5155 - val_loss: 0.7667 - val_accuracy: 0.4377\n",
      "Epoch 2/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6989 - accuracy: 0.5104\n",
      "Epoch 2: val_loss improved from 0.76668 to 0.71015, saving model to CNN_models/last_model_CNN_3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 139ms/step - loss: 0.6988 - accuracy: 0.5107 - val_loss: 0.7101 - val_accuracy: 0.5160\n",
      "Epoch 3/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6957 - accuracy: 0.5110\n",
      "Epoch 3: val_loss did not improve from 0.71015\n",
      "62/62 [==============================] - 7s 115ms/step - loss: 0.6957 - accuracy: 0.5111 - val_loss: 0.7187 - val_accuracy: 0.4771\n",
      "Epoch 4/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.5149\n",
      "Epoch 4: val_loss improved from 0.71015 to 0.68634, saving model to CNN_models/last_model_CNN_3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 140ms/step - loss: 0.6939 - accuracy: 0.5149 - val_loss: 0.6863 - val_accuracy: 0.5565\n",
      "Epoch 5/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6924 - accuracy: 0.5142\n",
      "Epoch 5: val_loss improved from 0.68634 to 0.68361, saving model to CNN_models/last_model_CNN_3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 137ms/step - loss: 0.6924 - accuracy: 0.5140 - val_loss: 0.6836 - val_accuracy: 0.5686\n",
      "Epoch 6/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.5169\n",
      "Epoch 6: val_loss did not improve from 0.68361\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.6922 - accuracy: 0.5170 - val_loss: 0.6926 - val_accuracy: 0.5354\n",
      "Epoch 7/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5146\n",
      "Epoch 7: val_loss did not improve from 0.68361\n",
      "62/62 [==============================] - 7s 117ms/step - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.7005 - val_accuracy: 0.4704\n",
      "Epoch 8/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6923 - accuracy: 0.5173\n",
      "Epoch 8: val_loss did not improve from 0.68361\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.6924 - accuracy: 0.5172 - val_loss: 0.6969 - val_accuracy: 0.5033\n",
      "Epoch 8: early stopping\n",
      "Epoch 1/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.7132 - accuracy: 0.5372\n",
      "Epoch 1: val_loss improved from inf to 1.14575, saving model to CNN_models/last_model_CNN_4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 11s 151ms/step - loss: 0.7132 - accuracy: 0.5370 - val_loss: 1.1458 - val_accuracy: 0.0466\n",
      "Epoch 2/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6851 - accuracy: 0.5690\n",
      "Epoch 2: val_loss improved from 1.14575 to 0.99847, saving model to CNN_models/last_model_CNN_4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 144ms/step - loss: 0.6852 - accuracy: 0.5688 - val_loss: 0.9985 - val_accuracy: 0.0351\n",
      "Epoch 3/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6788 - accuracy: 0.5887\n",
      "Epoch 3: val_loss improved from 0.99847 to 0.89250, saving model to CNN_models/last_model_CNN_4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 147ms/step - loss: 0.6788 - accuracy: 0.5887 - val_loss: 0.8925 - val_accuracy: 0.0129\n",
      "Epoch 4/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6735 - accuracy: 0.6026\n",
      "Epoch 4: val_loss did not improve from 0.89250\n",
      "62/62 [==============================] - 8s 122ms/step - loss: 0.6733 - accuracy: 0.6029 - val_loss: 1.0867 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.6034\n",
      "Epoch 5: val_loss did not improve from 0.89250\n",
      "62/62 [==============================] - 8s 123ms/step - loss: 0.6722 - accuracy: 0.6034 - val_loss: 0.9184 - val_accuracy: 1.2770e-04\n",
      "Epoch 6/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.6041\n",
      "Epoch 6: val_loss did not improve from 0.89250\n",
      "62/62 [==============================] - 8s 123ms/step - loss: 0.6705 - accuracy: 0.6041 - val_loss: 0.9258 - val_accuracy: 0.0000e+00\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.7261 - accuracy: 0.5239\n",
      "Epoch 1: val_loss improved from inf to 1.18667, saving model to CNN_models/last_model_CNN_5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 11s 152ms/step - loss: 0.7260 - accuracy: 0.5240 - val_loss: 1.1867 - val_accuracy: 0.0372\n",
      "Epoch 2/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6868 - accuracy: 0.5675\n",
      "Epoch 2: val_loss improved from 1.18667 to 1.03798, saving model to CNN_models/last_model_CNN_5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 141ms/step - loss: 0.6868 - accuracy: 0.5674 - val_loss: 1.0380 - val_accuracy: 0.0240\n",
      "Epoch 3/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6804 - accuracy: 0.5891\n",
      "Epoch 3: val_loss improved from 1.03798 to 0.96828, saving model to CNN_models/last_model_CNN_5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 138ms/step - loss: 0.6806 - accuracy: 0.5889 - val_loss: 0.9683 - val_accuracy: 0.0054\n",
      "Epoch 4/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6773 - accuracy: 0.5961\n",
      "Epoch 4: val_loss did not improve from 0.96828\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.6772 - accuracy: 0.5961 - val_loss: 1.0039 - val_accuracy: 1.2770e-04\n",
      "Epoch 5/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6723 - accuracy: 0.6038\n",
      "Epoch 5: val_loss did not improve from 0.96828\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 0.6723 - accuracy: 0.6039 - val_loss: 1.1149 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.6042\n",
      "Epoch 6: val_loss improved from 0.96828 to 0.90969, saving model to CNN_models/last_model_CNN_5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 141ms/step - loss: 0.6721 - accuracy: 0.6040 - val_loss: 0.9097 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.6042\n",
      "Epoch 7: val_loss improved from 0.90969 to 0.89765, saving model to CNN_models/last_model_CNN_5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 137ms/step - loss: 0.6711 - accuracy: 0.6040 - val_loss: 0.8976 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.6039\n",
      "Epoch 8: val_loss did not improve from 0.89765\n",
      "62/62 [==============================] - 7s 117ms/step - loss: 0.6707 - accuracy: 0.6041 - val_loss: 1.1034 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.6041\n",
      "Epoch 9: val_loss improved from 0.89765 to 0.86519, saving model to CNN_models/last_model_CNN_5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_models/last_model_CNN_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 140ms/step - loss: 0.6708 - accuracy: 0.6041 - val_loss: 0.8652 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.6039\n",
      "Epoch 10: val_loss did not improve from 0.86519\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 0.6702 - accuracy: 0.6041 - val_loss: 0.9479 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.6045\n",
      "Epoch 11: val_loss did not improve from 0.86519\n",
      "62/62 [==============================] - 7s 117ms/step - loss: 0.6707 - accuracy: 0.6041 - val_loss: 0.8669 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "61/62 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.6042\n",
      "Epoch 12: val_loss did not improve from 0.86519\n",
      "62/62 [==============================] - 7s 114ms/step - loss: 0.6707 - accuracy: 0.6041 - val_loss: 0.9075 - val_accuracy: 0.0000e+00\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    BATCH_SIZE = 512\n",
    "    with tf.device('CPU'):\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=len(y_train)).batch(BATCH_SIZE)\n",
    "        # del X_train, y_train\n",
    "\n",
    "        valid_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "        valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    save_model_name = f'CNN_models/last_model_CNN_fold_{fold+1}/'\n",
    "\n",
    "    # Create the model  \n",
    "    model = CNN()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=min_delta, verbose=1, patience=patience)\n",
    "    check_point = tf.keras.callbacks.ModelCheckpoint(save_model_name, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "    history = model.fit(train_dataset, validation_data=valid_dataset, epochs=train_epochs,\n",
    "                        callbacks=[early_stopping,\n",
    "                                   check_point,\n",
    "                                ]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2a71a",
   "metadata": {},
   "source": [
    "# Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d92c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = f'../Sample/HVmodel/data/split_val/25x25/mix_sample_test.npy'\n",
    "X_test, y_test = utils.load_samples(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476018bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6736 - accuracy: 0.5168\n",
      "Testing Loss = 0.674, Testing Accuracy = 0.517\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6805 - accuracy: 0.5081\n",
      "Testing Loss = 0.68, Testing Accuracy = 0.508\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6706 - accuracy: 0.6475\n",
      "Testing Loss = 0.671, Testing Accuracy = 0.647\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6574 - accuracy: 0.4975\n",
      "Testing Loss = 0.657, Testing Accuracy = 0.498\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6997 - accuracy: 0.5000\n",
      "Testing Loss = 0.7, Testing Accuracy = 0.5\n"
     ]
    }
   ],
   "source": [
    "for fold in range(k):\n",
    "    model_path = f'CNN_models/last_model_CNN_{fold+1}/'\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    results = loaded_model.evaluate(x=X_test, y=y_test, batch_size=BATCH_SIZE)\n",
    "    print(f'Testing Loss = {results[0]:.3}, Testing Accuracy = {results[1]:.3}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
